<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Binary Classification · UnifiedMetrics.jl</title><meta name="title" content="Binary Classification · UnifiedMetrics.jl"/><meta property="og:title" content="Binary Classification · UnifiedMetrics.jl"/><meta property="twitter:title" content="Binary Classification · UnifiedMetrics.jl"/><meta name="description" content="Documentation for UnifiedMetrics.jl."/><meta property="og:description" content="Documentation for UnifiedMetrics.jl."/><meta property="twitter:description" content="Documentation for UnifiedMetrics.jl."/><meta property="og:url" content="https://taf-society.github.io/UnifiedMetrics.jl/binary_classification/"/><meta property="twitter:url" content="https://taf-society.github.io/UnifiedMetrics.jl/binary_classification/"/><link rel="canonical" href="https://taf-society.github.io/UnifiedMetrics.jl/binary_classification/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">UnifiedMetrics.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../getting_started/">Getting Started</a></li><li><a class="tocitem" href="../choosing_metrics/">Choosing the Right Metric</a></li><li><a class="tocitem" href="../time_series/">Time Series Forecasting</a></li><li><span class="tocitem">Other Metrics</span><ul><li><a class="tocitem" href="../regression/">Regression</a></li><li><a class="tocitem" href="../classification/">Classification</a></li><li class="is-active"><a class="tocitem" href>Binary Classification</a><ul class="internal"><li><a class="tocitem" href="#Overview"><span>Overview</span></a></li><li><a class="tocitem" href="#Quick-Reference"><span>Quick Reference</span></a></li><li><a class="tocitem" href="#ROC-Based-Metrics"><span>ROC-Based Metrics</span></a></li><li><a class="tocitem" href="#Probability-Calibration-Metrics"><span>Probability Calibration Metrics</span></a></li><li><a class="tocitem" href="#Precision-and-Recall"><span>Precision and Recall</span></a></li><li><a class="tocitem" href="#F-Score"><span>F-Score</span></a></li><li><a class="tocitem" href="#Specificity-and-NPV"><span>Specificity and NPV</span></a></li><li><a class="tocitem" href="#Error-Rates"><span>Error Rates</span></a></li><li><a class="tocitem" href="#Combined-Metrics"><span>Combined Metrics</span></a></li><li><a class="tocitem" href="#Likelihood-Ratios-(Medical/Diagnostic)"><span>Likelihood Ratios (Medical/Diagnostic)</span></a></li><li><a class="tocitem" href="#Business-Metrics"><span>Business Metrics</span></a></li><li><a class="tocitem" href="#Usage-Examples"><span>Usage Examples</span></a></li></ul></li><li><a class="tocitem" href="../information_retrieval/">Information Retrieval</a></li></ul></li><li><a class="tocitem" href="../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Other Metrics</a></li><li class="is-active"><a href>Binary Classification</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Binary Classification</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/taf-society/UnifiedMetrics.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/main/docs/src/binary_classification.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Binary-Classification-Metrics"><a class="docs-heading-anchor" href="#Binary-Classification-Metrics">Binary Classification Metrics</a><a id="Binary-Classification-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Binary-Classification-Metrics" title="Permalink"></a></h1><p>Metrics for evaluating models that predict between two classes (positive/negative, yes/no, 1/0).</p><h2 id="Overview"><a class="docs-heading-anchor" href="#Overview">Overview</a><a id="Overview-1"></a><a class="docs-heading-anchor-permalink" href="#Overview" title="Permalink"></a></h2><p>Binary classification metrics fall into two categories:</p><ol><li><strong>Threshold-dependent</strong>: Require binary predictions (0/1)<ul><li>Precision, Recall, F-score, Specificity</li></ul></li><li><strong>Threshold-independent</strong>: Use probability scores<ul><li>AUC, Brier score, Log loss</li></ul></li></ol><h2 id="Quick-Reference"><a class="docs-heading-anchor" href="#Quick-Reference">Quick Reference</a><a id="Quick-Reference-1"></a><a class="docs-heading-anchor-permalink" href="#Quick-Reference" title="Permalink"></a></h2><table><tr><th style="text-align: right">Metric</th><th style="text-align: right">Input Type</th><th style="text-align: right">Range</th><th style="text-align: right">Best For</th></tr><tr><td style="text-align: right"><code>auc</code></td><td style="text-align: right">Probabilities</td><td style="text-align: right">[0, 1]</td><td style="text-align: right">Model comparison</td></tr><tr><td style="text-align: right"><code>precision</code></td><td style="text-align: right">Labels</td><td style="text-align: right">[0, 1]</td><td style="text-align: right">Minimizing FP</td></tr><tr><td style="text-align: right"><code>recall</code></td><td style="text-align: right">Labels</td><td style="text-align: right">[0, 1]</td><td style="text-align: right">Minimizing FN</td></tr><tr><td style="text-align: right"><code>fbeta_score</code></td><td style="text-align: right">Labels</td><td style="text-align: right">[0, 1]</td><td style="text-align: right">Balanced evaluation</td></tr><tr><td style="text-align: right"><code>mcc</code></td><td style="text-align: right">Labels</td><td style="text-align: right">[-1, 1]</td><td style="text-align: right">Imbalanced data</td></tr><tr><td style="text-align: right"><code>brier_score</code></td><td style="text-align: right">Probabilities</td><td style="text-align: right">[0, 1]</td><td style="text-align: right">Calibration</td></tr></table><h2 id="ROC-Based-Metrics"><a class="docs-heading-anchor" href="#ROC-Based-Metrics">ROC-Based Metrics</a><a id="ROC-Based-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#ROC-Based-Metrics" title="Permalink"></a></h2><h3 id="Area-Under-ROC-Curve"><a class="docs-heading-anchor" href="#Area-Under-ROC-Curve">Area Under ROC Curve</a><a id="Area-Under-ROC-Curve-1"></a><a class="docs-heading-anchor-permalink" href="#Area-Under-ROC-Curve" title="Permalink"></a></h3><pre><code class="language-julia hljs">auc(actual, predicted_probs)</code></pre><p><strong>Interpretation</strong>:</p><ul><li>AUC = 1.0: Perfect ranking</li><li>AUC = 0.5: Random guessing</li><li>AUC &lt; 0.5: Worse than random (flip predictions!)</li></ul><p><strong>Guidelines</strong>:</p><ul><li>0.9-1.0: Excellent</li><li>0.8-0.9: Good</li><li>0.7-0.8: Fair</li><li>0.6-0.7: Poor</li><li>0.5-0.6: Fail</li></ul><h3 id="Gini-Coefficient"><a class="docs-heading-anchor" href="#Gini-Coefficient">Gini Coefficient</a><a id="Gini-Coefficient-1"></a><a class="docs-heading-anchor-permalink" href="#Gini-Coefficient" title="Permalink"></a></h3><pre><code class="language-julia hljs">gini_coefficient(actual, predicted_probs)</code></pre><p><strong>Relationship</strong>: Gini = 2 × AUC - 1</p><h3 id="KS-Statistic"><a class="docs-heading-anchor" href="#KS-Statistic">KS Statistic</a><a id="KS-Statistic-1"></a><a class="docs-heading-anchor-permalink" href="#KS-Statistic" title="Permalink"></a></h3><pre><code class="language-julia hljs">ks_statistic(actual, predicted_probs)</code></pre><p><strong>When to use</strong>: Credit scoring, marketing response modeling.</p><h2 id="Probability-Calibration-Metrics"><a class="docs-heading-anchor" href="#Probability-Calibration-Metrics">Probability Calibration Metrics</a><a id="Probability-Calibration-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Probability-Calibration-Metrics" title="Permalink"></a></h2><h3 id="Log-Loss"><a class="docs-heading-anchor" href="#Log-Loss">Log Loss</a><a id="Log-Loss-1"></a><a class="docs-heading-anchor-permalink" href="#Log-Loss" title="Permalink"></a></h3><pre><code class="language-julia hljs">ll(actual, predicted_probs)      # Elementwise
logloss(actual, predicted_probs) # Mean</code></pre><p><strong>When to use</strong>:</p><ul><li>Training neural networks (cross-entropy loss)</li><li>When probability values matter, not just ranking</li></ul><h3 id="Brier-Score"><a class="docs-heading-anchor" href="#Brier-Score">Brier Score</a><a id="Brier-Score-1"></a><a class="docs-heading-anchor-permalink" href="#Brier-Score" title="Permalink"></a></h3><pre><code class="language-julia hljs">brier_score(actual, predicted_probs)</code></pre><p><strong>Interpretation</strong>:</p><ul><li>0: Perfect calibration</li><li>0.25: Random guessing for balanced data</li><li>1: Complete miscalibration</li></ul><p><strong>When to use</strong>: Weather forecasting, medical prognosis - anywhere probability calibration matters.</p><h2 id="Precision-and-Recall"><a class="docs-heading-anchor" href="#Precision-and-Recall">Precision and Recall</a><a id="Precision-and-Recall-1"></a><a class="docs-heading-anchor-permalink" href="#Precision-and-Recall" title="Permalink"></a></h2><h3 id="Precision-(Positive-Predictive-Value)"><a class="docs-heading-anchor" href="#Precision-(Positive-Predictive-Value)">Precision (Positive Predictive Value)</a><a id="Precision-(Positive-Predictive-Value)-1"></a><a class="docs-heading-anchor-permalink" href="#Precision-(Positive-Predictive-Value)" title="Permalink"></a></h3><pre><code class="language-julia hljs">precision(actual, predicted_labels)</code></pre><p><strong>Interpretation</strong>: Of all samples predicted positive, what fraction are actually positive?</p><p><strong>Optimize for precision when</strong>: False positives are costly</p><ul><li>Spam detection (don&#39;t mark good email as spam)</li><li>Legal discovery (don&#39;t flag innocent documents)</li></ul><h3 id="Recall-(Sensitivity,-True-Positive-Rate)"><a class="docs-heading-anchor" href="#Recall-(Sensitivity,-True-Positive-Rate)">Recall (Sensitivity, True Positive Rate)</a><a id="Recall-(Sensitivity,-True-Positive-Rate)-1"></a><a class="docs-heading-anchor-permalink" href="#Recall-(Sensitivity,-True-Positive-Rate)" title="Permalink"></a></h3><pre><code class="language-julia hljs">recall(actual, predicted_labels)
sensitivity(actual, predicted_labels)  # Alias</code></pre><p><strong>Interpretation</strong>: Of all actual positives, what fraction did we detect?</p><p><strong>Optimize for recall when</strong>: False negatives are costly</p><ul><li>Disease screening (don&#39;t miss sick patients)</li><li>Fraud detection (don&#39;t miss fraudulent transactions)</li><li>Security threats (don&#39;t miss actual threats)</li></ul><h2 id="F-Score"><a class="docs-heading-anchor" href="#F-Score">F-Score</a><a id="F-Score-1"></a><a class="docs-heading-anchor-permalink" href="#F-Score" title="Permalink"></a></h2><pre><code class="language-julia hljs">fbeta_score(actual, predicted_labels; beta=1.0)</code></pre><p><strong>Choosing beta</strong>:</p><ul><li>β = 1: Equal weight to precision and recall (F1)</li><li>β = 0.5: Precision weighted 2× more than recall</li><li>β = 2: Recall weighted 2× more than precision</li></ul><p><strong>Formula</strong>: F_β = (1 + β²) × (precision × recall) / (β² × precision + recall)</p><h2 id="Specificity-and-NPV"><a class="docs-heading-anchor" href="#Specificity-and-NPV">Specificity and NPV</a><a id="Specificity-and-NPV-1"></a><a class="docs-heading-anchor-permalink" href="#Specificity-and-NPV" title="Permalink"></a></h2><pre><code class="language-julia hljs">specificity(actual, predicted_labels)
npv(actual, predicted_labels)</code></pre><p><strong>Relationships</strong>:</p><ul><li>Sensitivity (recall) + FNR = 1</li><li>Specificity + FPR = 1</li><li>Precision + FDR = 1</li><li>NPV + FOR = 1</li></ul><h2 id="Error-Rates"><a class="docs-heading-anchor" href="#Error-Rates">Error Rates</a><a id="Error-Rates-1"></a><a class="docs-heading-anchor-permalink" href="#Error-Rates" title="Permalink"></a></h2><pre><code class="language-julia hljs">fpr(actual, predicted_labels)  # False Positive Rate
fnr(actual, predicted_labels)  # False Negative Rate</code></pre><h2 id="Combined-Metrics"><a class="docs-heading-anchor" href="#Combined-Metrics">Combined Metrics</a><a id="Combined-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Combined-Metrics" title="Permalink"></a></h2><h3 id="Youden&#39;s-J-(Informedness)"><a class="docs-heading-anchor" href="#Youden&#39;s-J-(Informedness)">Youden&#39;s J (Informedness)</a><a id="Youden&#39;s-J-(Informedness)-1"></a><a class="docs-heading-anchor-permalink" href="#Youden&#39;s-J-(Informedness)" title="Permalink"></a></h3><pre><code class="language-julia hljs">youden_j(actual, predicted_labels)</code></pre><p><strong>Use case</strong>: Finding optimal threshold that maximizes sensitivity + specificity.</p><h3 id="Markedness"><a class="docs-heading-anchor" href="#Markedness">Markedness</a><a id="Markedness-1"></a><a class="docs-heading-anchor-permalink" href="#Markedness" title="Permalink"></a></h3><pre><code class="language-julia hljs">markedness(actual, predicted_labels)</code></pre><p><strong>Interpretation</strong>: How marked (informative) are positive and negative predictions?</p><h3 id="Fowlkes-Mallows-Index"><a class="docs-heading-anchor" href="#Fowlkes-Mallows-Index">Fowlkes-Mallows Index</a><a id="Fowlkes-Mallows-Index-1"></a><a class="docs-heading-anchor-permalink" href="#Fowlkes-Mallows-Index" title="Permalink"></a></h3><pre><code class="language-julia hljs">fowlkes_mallows_index(actual, predicted_labels)</code></pre><h2 id="Likelihood-Ratios-(Medical/Diagnostic)"><a class="docs-heading-anchor" href="#Likelihood-Ratios-(Medical/Diagnostic)">Likelihood Ratios (Medical/Diagnostic)</a><a id="Likelihood-Ratios-(Medical/Diagnostic)-1"></a><a class="docs-heading-anchor-permalink" href="#Likelihood-Ratios-(Medical/Diagnostic)" title="Permalink"></a></h2><pre><code class="language-julia hljs">positive_likelihood_ratio(actual, predicted_labels)
negative_likelihood_ratio(actual, predicted_labels)
diagnostic_odds_ratio(actual, predicted_labels)</code></pre><p><strong>Interpretation of LR+</strong>:</p><ul><li>LR+ &gt; 10: Strong evidence for positive</li><li>LR+ = 5-10: Moderate evidence</li><li>LR+ = 2-5: Weak evidence</li><li>LR+ = 1: Useless test</li></ul><p><strong>Interpretation of LR-</strong>:</p><ul><li>LR- &lt; 0.1: Strong evidence for negative</li><li>LR- = 0.1-0.2: Moderate evidence</li><li>LR- = 0.2-0.5: Weak evidence</li><li>LR- = 1: Useless test</li></ul><h2 id="Business-Metrics"><a class="docs-heading-anchor" href="#Business-Metrics">Business Metrics</a><a id="Business-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Business-Metrics" title="Permalink"></a></h2><h3 id="Lift"><a class="docs-heading-anchor" href="#Lift">Lift</a><a id="Lift-1"></a><a class="docs-heading-anchor-permalink" href="#Lift" title="Permalink"></a></h3><pre><code class="language-julia hljs">lift(actual, predicted_probs; percentile=0.1)</code></pre><p><strong>Interpretation</strong>: How many times better than random in the top X%?</p><ul><li>Lift = 3 in top 10%: 3× more positives than random</li></ul><h3 id="Gain"><a class="docs-heading-anchor" href="#Gain">Gain</a><a id="Gain-1"></a><a class="docs-heading-anchor-permalink" href="#Gain" title="Permalink"></a></h3><pre><code class="language-julia hljs">gain(actual, predicted_probs; percentile=0.1)</code></pre><p><strong>Interpretation</strong>: What percentage of all positives are captured in top X%?</p><h2 id="Usage-Examples"><a class="docs-heading-anchor" href="#Usage-Examples">Usage Examples</a><a id="Usage-Examples-1"></a><a class="docs-heading-anchor-permalink" href="#Usage-Examples" title="Permalink"></a></h2><h3 id="Complete-Binary-Classification-Evaluation"><a class="docs-heading-anchor" href="#Complete-Binary-Classification-Evaluation">Complete Binary Classification Evaluation</a><a id="Complete-Binary-Classification-Evaluation-1"></a><a class="docs-heading-anchor-permalink" href="#Complete-Binary-Classification-Evaluation" title="Permalink"></a></h3><pre><code class="language-julia hljs">using UnifiedMetrics

actual = [1, 1, 1, 1, 0, 0, 0, 0, 0, 0]
predicted_probs = [0.9, 0.8, 0.7, 0.3, 0.6, 0.4, 0.35, 0.2, 0.1, 0.05]
predicted_labels = predicted_probs .&gt;= 0.5

println(&quot;=== Threshold-Independent ===&quot;)
println(&quot;AUC: &quot;, round(auc(actual, predicted_probs), digits=3))
println(&quot;Gini: &quot;, round(gini_coefficient(actual, predicted_probs), digits=3))
println(&quot;KS Statistic: &quot;, round(ks_statistic(actual, predicted_probs), digits=3))
println(&quot;Brier Score: &quot;, round(brier_score(actual, predicted_probs), digits=3))
println(&quot;Log Loss: &quot;, round(logloss(actual, predicted_probs), digits=3))

println(&quot;\n=== Threshold-Dependent (threshold=0.5) ===&quot;)
println(&quot;Precision: &quot;, round(precision(actual, predicted_labels), digits=3))
println(&quot;Recall: &quot;, round(recall(actual, predicted_labels), digits=3))
println(&quot;F1 Score: &quot;, round(fbeta_score(actual, predicted_labels), digits=3))
println(&quot;Specificity: &quot;, round(specificity(actual, predicted_labels), digits=3))
println(&quot;MCC: &quot;, round(mcc(actual, predicted_labels), digits=3))</code></pre><h3 id="Comparing-Different-Thresholds"><a class="docs-heading-anchor" href="#Comparing-Different-Thresholds">Comparing Different Thresholds</a><a id="Comparing-Different-Thresholds-1"></a><a class="docs-heading-anchor-permalink" href="#Comparing-Different-Thresholds" title="Permalink"></a></h3><pre><code class="language-julia hljs">using UnifiedMetrics

actual = [1, 1, 1, 1, 0, 0, 0, 0, 0, 0]
probs = [0.9, 0.8, 0.7, 0.3, 0.6, 0.4, 0.35, 0.2, 0.1, 0.05]

for threshold in [0.3, 0.5, 0.7]
    labels = probs .&gt;= threshold
    println(&quot;Threshold: $threshold&quot;)
    println(&quot;  Precision: $(round(precision(actual, labels), digits=2))&quot;)
    println(&quot;  Recall: $(round(recall(actual, labels), digits=2))&quot;)
    println(&quot;  F1: $(round(fbeta_score(actual, labels), digits=2))&quot;)
    println(&quot;  Youden&#39;s J: $(round(youden_j(actual, labels), digits=2))&quot;)
end</code></pre><h3 id="Medical-Diagnostic-Evaluation"><a class="docs-heading-anchor" href="#Medical-Diagnostic-Evaluation">Medical Diagnostic Evaluation</a><a id="Medical-Diagnostic-Evaluation-1"></a><a class="docs-heading-anchor-permalink" href="#Medical-Diagnostic-Evaluation" title="Permalink"></a></h3><pre><code class="language-julia hljs">using UnifiedMetrics

# Disease screening results
actual = [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]  # 1 = has disease
predicted = [1, 1, 1, 0, 0, 0, 0, 0, 1, 0]  # Test results

println(&quot;=== Diagnostic Performance ===&quot;)
println(&quot;Sensitivity: &quot;, round(sensitivity(actual, predicted), digits=3))
println(&quot;Specificity: &quot;, round(specificity(actual, predicted), digits=3))
println(&quot;PPV (Precision): &quot;, round(precision(actual, predicted), digits=3))
println(&quot;NPV: &quot;, round(npv(actual, predicted), digits=3))
println(&quot;LR+: &quot;, round(positive_likelihood_ratio(actual, predicted), digits=2))
println(&quot;LR-: &quot;, round(negative_likelihood_ratio(actual, predicted), digits=2))
println(&quot;DOR: &quot;, round(diagnostic_odds_ratio(actual, predicted), digits=1))</code></pre><h3 id="Marketing/Business-Application"><a class="docs-heading-anchor" href="#Marketing/Business-Application">Marketing/Business Application</a><a id="Marketing/Business-Application-1"></a><a class="docs-heading-anchor-permalink" href="#Marketing/Business-Application" title="Permalink"></a></h3><pre><code class="language-julia hljs">using UnifiedMetrics

# Customer response prediction
actual_responded = [1, 1, 1, 0, 0, 0, 0, 0, 0, 0]
predicted_scores = [0.9, 0.8, 0.3, 0.7, 0.6, 0.5, 0.4, 0.2, 0.1, 0.05]

println(&quot;=== Campaign Targeting ===&quot;)
for pct in [0.1, 0.2, 0.3, 0.5]
    println(&quot;Top $(Int(pct*100))%:&quot;)
    println(&quot;  Lift: $(round(lift(actual_responded, predicted_scores, percentile=pct), digits=2))x&quot;)
    println(&quot;  Gain: $(round(gain(actual_responded, predicted_scores, percentile=pct)*100, digits=1))%&quot;)
end</code></pre><h3 id="Handling-Imbalanced-Data"><a class="docs-heading-anchor" href="#Handling-Imbalanced-Data">Handling Imbalanced Data</a><a id="Handling-Imbalanced-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Handling-Imbalanced-Data" title="Permalink"></a></h3><pre><code class="language-julia hljs">using UnifiedMetrics

# Highly imbalanced: 95% negative, 5% positive
actual = vcat(fill(0, 95), fill(1, 5))
predicted = vcat(fill(0, 100))  # Naive: always predict negative

println(&quot;=== Naive Model on Imbalanced Data ===&quot;)
println(&quot;Accuracy: &quot;, accuracy(actual, predicted))  # 0.95 - misleading!
println(&quot;Recall: &quot;, recall(actual, predicted))       # 0.0 - reveals the problem
println(&quot;MCC: &quot;, mcc(actual, predicted))             # 0.0 - correctly shows failure

# A better model
predicted_better = vcat(fill(0, 90), fill(1, 5), fill(0, 3), fill(1, 2))
println(&quot;\n=== Better Model ===&quot;)
println(&quot;Accuracy: &quot;, accuracy(actual, predicted_better))
println(&quot;Recall: &quot;, recall(actual, predicted_better))
println(&quot;Precision: &quot;, precision(actual, predicted_better))
println(&quot;MCC: &quot;, round(mcc(actual, predicted_better), digits=3))</code></pre><p>See the <a href="../api/#API-Reference">API Reference</a> for complete function documentation.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../classification/">« Classification</a><a class="docs-footer-nextpage" href="../information_retrieval/">Information Retrieval »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Friday 30 January 2026 11:34">Friday 30 January 2026</span>. Using Julia version 1.11.8.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
