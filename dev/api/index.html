<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API Reference · UnifiedMetrics.jl</title><meta name="title" content="API Reference · UnifiedMetrics.jl"/><meta property="og:title" content="API Reference · UnifiedMetrics.jl"/><meta property="twitter:title" content="API Reference · UnifiedMetrics.jl"/><meta name="description" content="Documentation for UnifiedMetrics.jl."/><meta property="og:description" content="Documentation for UnifiedMetrics.jl."/><meta property="twitter:description" content="Documentation for UnifiedMetrics.jl."/><meta property="og:url" content="https://taf-society.github.io/UnifiedMetrics.jl/api/"/><meta property="twitter:url" content="https://taf-society.github.io/UnifiedMetrics.jl/api/"/><link rel="canonical" href="https://taf-society.github.io/UnifiedMetrics.jl/api/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">UnifiedMetrics.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../getting_started/">Getting Started</a></li><li><a class="tocitem" href="../choosing_metrics/">Choosing the Right Metric</a></li><li><a class="tocitem" href="../time_series/">Time Series Forecasting</a></li><li><span class="tocitem">Other Metrics</span><ul><li><a class="tocitem" href="../regression/">Regression</a></li><li><a class="tocitem" href="../classification/">Classification</a></li><li><a class="tocitem" href="../binary_classification/">Binary Classification</a></li><li><a class="tocitem" href="../information_retrieval/">Information Retrieval</a></li></ul></li><li class="is-active"><a class="tocitem" href>API Reference</a><ul class="internal"><li><a class="tocitem" href="#Regression-Metrics"><span>Regression Metrics</span></a></li><li><a class="tocitem" href="#Classification-Metrics"><span>Classification Metrics</span></a></li><li><a class="tocitem" href="#Binary-Classification-Metrics"><span>Binary Classification Metrics</span></a></li><li><a class="tocitem" href="#Information-Retrieval-Metrics"><span>Information Retrieval Metrics</span></a></li><li><a class="tocitem" href="#Time-Series-Metrics"><span>Time Series Metrics</span></a></li><li><a class="tocitem" href="#Index"><span>Index</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>API Reference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>API Reference</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/taf-society/UnifiedMetrics.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/main/docs/src/api.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="API-Reference"><a class="docs-heading-anchor" href="#API-Reference">API Reference</a><a id="API-Reference-1"></a><a class="docs-heading-anchor-permalink" href="#API-Reference" title="Permalink"></a></h1><p>Complete reference for all functions in UnifiedMetrics.jl.</p><h2 id="Regression-Metrics"><a class="docs-heading-anchor" href="#Regression-Metrics">Regression Metrics</a><a id="Regression-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Regression-Metrics" title="Permalink"></a></h2><h3 id="Error-Metrics"><a class="docs-heading-anchor" href="#Error-Metrics">Error Metrics</a><a id="Error-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Error-Metrics" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.ae"><a class="docstring-binding" href="#UnifiedMetrics.ae"><code>UnifiedMetrics.ae</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">ae(actual, predicted)</code></pre><p>Compute the elementwise absolute error between two numeric vectors.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth numeric vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted numeric vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
ae(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L129-L144">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.mae"><a class="docstring-binding" href="#UnifiedMetrics.mae"><code>UnifiedMetrics.mae</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">mae(actual, predicted)</code></pre><p>Compute the mean absolute error between two numeric vectors.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth numeric vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted numeric vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
mae(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L150-L165">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.mdae"><a class="docstring-binding" href="#UnifiedMetrics.mdae"><code>UnifiedMetrics.mdae</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">mdae(actual, predicted)</code></pre><p>Compute the median absolute error between two numeric vectors.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth numeric vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted numeric vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
mdae(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L170-L185">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.se"><a class="docstring-binding" href="#UnifiedMetrics.se"><code>UnifiedMetrics.se</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">se(actual, predicted)</code></pre><p>Compute the elementwise squared error between two numeric vectors.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth numeric vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted numeric vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
se(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L48-L63">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.sse"><a class="docstring-binding" href="#UnifiedMetrics.sse"><code>UnifiedMetrics.sse</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">sse(actual, predicted)</code></pre><p>Compute the sum of squared errors between two numeric vectors.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth numeric vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted numeric vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
sse(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L69-L84">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.mse"><a class="docstring-binding" href="#UnifiedMetrics.mse"><code>UnifiedMetrics.mse</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">mse(actual, predicted)</code></pre><p>Compute the mean squared error between two numeric vectors.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth numeric vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted numeric vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
mse(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L89-L104">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.rmse"><a class="docstring-binding" href="#UnifiedMetrics.rmse"><code>UnifiedMetrics.rmse</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">rmse(actual, predicted)</code></pre><p>Compute the root mean squared error between two numeric vectors.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth numeric vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted numeric vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
rmse(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L109-L124">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.nrmse"><a class="docstring-binding" href="#UnifiedMetrics.nrmse"><code>UnifiedMetrics.nrmse</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">nrmse(actual, predicted; normalization=:range)</code></pre><p>Compute the Normalized Root Mean Squared Error.</p><p>Normalizes RMSE to make it comparable across different scales.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth numeric vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted numeric vector</li><li><code>normalization::Symbol</code>: Normalization method (default: <code>:range</code>)<ul><li><code>:range</code> - Normalize by range (max - min) of actual values</li><li><code>:mean</code> - Normalize by mean of actual values (coefficient of variation of RMSE)</li><li><code>:std</code> - Normalize by standard deviation of actual values</li><li><code>:iqr</code> - Normalize by interquartile range of actual values</li></ul></li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
nrmse(actual, predicted)  # Normalized by range
nrmse(actual, predicted, normalization=:mean)  # CV(RMSE)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L564-L587">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.max_error"><a class="docstring-binding" href="#UnifiedMetrics.max_error"><code>UnifiedMetrics.max_error</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">max_error(actual, predicted)</code></pre><p>Compute the maximum absolute error between two numeric vectors.</p><p>Useful for understanding the worst-case prediction error.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth numeric vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted numeric vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
max_error(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L426-L443">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.max_ae"><a class="docstring-binding" href="#UnifiedMetrics.max_ae"><code>UnifiedMetrics.max_ae</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">max_ae(actual, predicted)</code></pre><p>Alias for <code>max_error</code>. Compute the maximum absolute error.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth numeric vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted numeric vector</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L449-L457">source</a></section></details></article><h3 id="Bias-Metrics"><a class="docs-heading-anchor" href="#Bias-Metrics">Bias Metrics</a><a id="Bias-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Bias-Metrics" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.bias"><a class="docstring-binding" href="#UnifiedMetrics.bias"><code>UnifiedMetrics.bias</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">bias(actual, predicted)</code></pre><p>Compute the average amount by which <code>actual</code> is greater than <code>predicted</code>.</p><p>If a model is unbiased, <code>bias(actual, predicted)</code> should be close to zero.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth numeric vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted numeric vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
bias(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L1-L18">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.percent_bias"><a class="docstring-binding" href="#UnifiedMetrics.percent_bias"><code>UnifiedMetrics.percent_bias</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">percent_bias(actual, predicted)</code></pre><p>Compute the average amount that <code>actual</code> is greater than <code>predicted</code> as a percentage of the absolute value of <code>actual</code>.</p><p>Returns <code>-Inf</code>, <code>Inf</code>, or <code>NaN</code> if any elements of <code>actual</code> are <code>0</code>.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth numeric vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted numeric vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
percent_bias(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L24-L42">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.mpe"><a class="docstring-binding" href="#UnifiedMetrics.mpe"><code>UnifiedMetrics.mpe</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">mpe(actual, predicted)</code></pre><p>Compute the Mean Percentage Error (signed).</p><p>Unlike MAPE, MPE can indicate systematic bias: positive values indicate under-prediction on average, negative values indicate over-prediction.</p><p>Returns <code>Inf</code>, <code>-Inf</code>, or <code>NaN</code> if <code>actual</code> contains zeros.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth numeric vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted numeric vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
mpe(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L637-L657">source</a></section></details></article><h3 id="Percentage-Error-Metrics"><a class="docs-heading-anchor" href="#Percentage-Error-Metrics">Percentage Error Metrics</a><a id="Percentage-Error-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Percentage-Error-Metrics" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.ape"><a class="docstring-binding" href="#UnifiedMetrics.ape"><code>UnifiedMetrics.ape</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">ape(actual, predicted)</code></pre><p>Compute the elementwise absolute percent error between two numeric vectors.</p><p>Returns <code>-Inf</code>, <code>Inf</code>, or <code>NaN</code> if <code>actual</code> contains zeros.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth numeric vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted numeric vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
ape(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L190-L207">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.mape"><a class="docstring-binding" href="#UnifiedMetrics.mape"><code>UnifiedMetrics.mape</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">mape(actual, predicted)</code></pre><p>Compute the mean absolute percent error between two numeric vectors.</p><p>Returns <code>-Inf</code>, <code>Inf</code>, or <code>NaN</code> if <code>actual</code> contains zeros. Due to instability at or near zero, <code>smape</code> or <code>mase</code> are often used as alternatives.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth numeric vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted numeric vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
mape(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L213-L231">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.smape"><a class="docstring-binding" href="#UnifiedMetrics.smape"><code>UnifiedMetrics.smape</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">smape(actual, predicted)</code></pre><p>Compute the symmetric mean absolute percentage error between two numeric vectors.</p><p>Defined as <code>2 * mean(abs(actual - predicted) / (abs(actual) + abs(predicted)))</code>. Returns <code>NaN</code> only if both <code>actual</code> and <code>predicted</code> are zero at the same position. Has an upper bound of 2.</p><p><code>smape</code> is symmetric: <code>smape(x, y) == smape(y, x)</code>.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth numeric vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted numeric vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
smape(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L236-L257">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.wmape"><a class="docstring-binding" href="#UnifiedMetrics.wmape"><code>UnifiedMetrics.wmape</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">wmape(actual, predicted)</code></pre><p>Compute the Weighted Mean Absolute Percentage Error.</p><p>WMAPE weights errors by the magnitude of actual values, making it more robust than MAPE when actual values vary significantly in magnitude.</p><p>WMAPE = sum(|actual - predicted|) / sum(|actual|)</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth numeric vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted numeric vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
wmape(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L663-L683">source</a></section></details></article><h3 id="Logarithmic-Error-Metrics"><a class="docs-heading-anchor" href="#Logarithmic-Error-Metrics">Logarithmic Error Metrics</a><a id="Logarithmic-Error-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Logarithmic-Error-Metrics" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.sle"><a class="docstring-binding" href="#UnifiedMetrics.sle"><code>UnifiedMetrics.sle</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">sle(actual, predicted)</code></pre><p>Compute the elementwise squared log error between two numeric vectors.</p><p>Adds one to both <code>actual</code> and <code>predicted</code> before taking the natural logarithm to avoid taking the log of zero. Not appropriate for negative values.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth non-negative vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted non-negative vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
sle(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L263-L281">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.msle"><a class="docstring-binding" href="#UnifiedMetrics.msle"><code>UnifiedMetrics.msle</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">msle(actual, predicted)</code></pre><p>Compute the mean squared log error between two numeric vectors.</p><p>Adds one to both <code>actual</code> and <code>predicted</code> before taking the natural logarithm to avoid taking the log of zero. Not appropriate for negative values.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth non-negative vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted non-negative vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
msle(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L287-L305">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.rmsle"><a class="docstring-binding" href="#UnifiedMetrics.rmsle"><code>UnifiedMetrics.rmsle</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">rmsle(actual, predicted)</code></pre><p>Compute the root mean squared log error between two numeric vectors.</p><p>Adds one to both <code>actual</code> and <code>predicted</code> before taking the natural logarithm to avoid taking the log of zero. Not appropriate for negative values.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth non-negative vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted non-negative vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
rmsle(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L310-L328">source</a></section></details></article><h3 id="Relative-Error-Metrics"><a class="docs-heading-anchor" href="#Relative-Error-Metrics">Relative Error Metrics</a><a id="Relative-Error-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Relative-Error-Metrics" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.rse"><a class="docstring-binding" href="#UnifiedMetrics.rse"><code>UnifiedMetrics.rse</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">rse(actual, predicted)</code></pre><p>Compute the relative squared error between two numeric vectors.</p><p>Divides <code>sse(actual, predicted)</code> by <code>sse(actual, mean(actual))</code>, providing the squared error relative to a naive model that predicts the mean for every data point.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth numeric vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted numeric vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
rse(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L333-L351">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.rrse"><a class="docstring-binding" href="#UnifiedMetrics.rrse"><code>UnifiedMetrics.rrse</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">rrse(actual, predicted)</code></pre><p>Compute the root relative squared error between two numeric vectors.</p><p>Takes the square root of <code>rse(actual, predicted)</code>.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth numeric vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted numeric vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
rrse(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L357-L374">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.rae"><a class="docstring-binding" href="#UnifiedMetrics.rae"><code>UnifiedMetrics.rae</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">rae(actual, predicted)</code></pre><p>Compute the relative absolute error between two numeric vectors.</p><p>Divides <code>sum(ae(actual, predicted))</code> by <code>sum(ae(actual, mean(actual)))</code>, providing the absolute error relative to a naive model that predicts the mean for every data point.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth numeric vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted numeric vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
rae(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L379-L397">source</a></section></details></article><h3 id="Explained-Variance"><a class="docs-heading-anchor" href="#Explained-Variance">Explained Variance</a><a id="Explained-Variance-1"></a><a class="docs-heading-anchor-permalink" href="#Explained-Variance" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.explained_variation"><a class="docstring-binding" href="#UnifiedMetrics.explained_variation"><code>UnifiedMetrics.explained_variation</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">explained_variation(actual, predicted)</code></pre><p>Compute the explained variation (coefficient of determination, R²) between two numeric vectors.</p><p>Subtracts <code>rse(actual, predicted)</code> from 1. Can return negative values if predictions are worse than predicting the mean.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth numeric vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted numeric vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
explained_variation(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L403-L421">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.adjusted_r2"><a class="docstring-binding" href="#UnifiedMetrics.adjusted_r2"><code>UnifiedMetrics.adjusted_r2</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">adjusted_r2(actual, predicted, n_features)</code></pre><p>Compute the Adjusted R² (coefficient of determination adjusted for number of predictors).</p><p>Adjusted R² penalizes the addition of irrelevant features to a model.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth numeric vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted numeric vector</li><li><code>n_features::Integer</code>: Number of features/predictors in the model</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
adjusted_r2(actual, predicted, 2)  # Model with 2 features</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L610-L628">source</a></section></details></article><h3 id="Robust-Loss-Functions"><a class="docs-heading-anchor" href="#Robust-Loss-Functions">Robust Loss Functions</a><a id="Robust-Loss-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Robust-Loss-Functions" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.huber_loss"><a class="docstring-binding" href="#UnifiedMetrics.huber_loss"><code>UnifiedMetrics.huber_loss</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">huber_loss(actual, predicted; delta=1.0)</code></pre><p>Compute the Huber loss, which is quadratic for small errors and linear for large errors.</p><p>Huber loss is less sensitive to outliers than MSE. For errors smaller than <code>delta</code>, it behaves like MSE; for larger errors, it behaves like MAE.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth numeric vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted numeric vector</li><li><code>delta::Real</code>: Threshold where loss transitions from quadratic to linear (default: 1.0)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
huber_loss(actual, predicted)
huber_loss(actual, predicted, delta=0.5)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L460-L480">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.log_cosh_loss"><a class="docstring-binding" href="#UnifiedMetrics.log_cosh_loss"><code>UnifiedMetrics.log_cosh_loss</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">log_cosh_loss(actual, predicted)</code></pre><p>Compute the log-cosh loss, a smooth approximation of MAE.</p><p>Log-cosh is approximately equal to <code>(x^2)/2</code> for small x and <code>abs(x) - log(2)</code> for large x. It has the advantage of being twice differentiable everywhere.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth numeric vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted numeric vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
log_cosh_loss(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L500-L518">source</a></section></details></article><h3 id="Quantile-Loss"><a class="docs-heading-anchor" href="#Quantile-Loss">Quantile Loss</a><a id="Quantile-Loss-1"></a><a class="docs-heading-anchor-permalink" href="#Quantile-Loss" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.quantile_loss"><a class="docstring-binding" href="#UnifiedMetrics.quantile_loss"><code>UnifiedMetrics.quantile_loss</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">quantile_loss(actual, predicted; quantile=0.5)</code></pre><p>Compute the quantile (pinball) loss for quantile regression.</p><p>The quantile loss asymmetrically penalizes over-prediction and under-prediction. At quantile=0.5, this is equivalent to MAE. For quantile&lt;0.5, under-prediction is penalized more; for quantile&gt;0.5, over-prediction is penalized more.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth numeric vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted numeric vector</li><li><code>quantile::Real</code>: Target quantile in (0, 1) (default: 0.5)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
quantile_loss(actual, predicted, quantile=0.5)  # Equivalent to MAE
quantile_loss(actual, predicted, quantile=0.9)  # Penalize under-prediction more</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L525-L546">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.pinball_loss"><a class="docstring-binding" href="#UnifiedMetrics.pinball_loss"><code>UnifiedMetrics.pinball_loss</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">pinball_loss(actual, predicted; quantile=0.5)</code></pre><p>Alias for <code>quantile_loss</code>. Compute the pinball loss for quantile regression.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L556-L560">source</a></section></details></article><h3 id="GLM-Deviance-Metrics"><a class="docs-heading-anchor" href="#GLM-Deviance-Metrics">GLM Deviance Metrics</a><a id="GLM-Deviance-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#GLM-Deviance-Metrics" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.tweedie_deviance"><a class="docstring-binding" href="#UnifiedMetrics.tweedie_deviance"><code>UnifiedMetrics.tweedie_deviance</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">tweedie_deviance(actual, predicted; power=1.5)</code></pre><p>Compute the Tweedie deviance for generalized linear models.</p><p>The power parameter controls the distribution assumption:</p><ul><li>power=0: Normal distribution (equivalent to MSE)</li><li>power=1: Poisson distribution</li><li>power=2: Gamma distribution</li><li>power=3: Inverse Gaussian distribution</li><li>1 &lt; power &lt; 2: Compound Poisson-Gamma (common for insurance claims)</li></ul><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth non-negative vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted non-negative vector</li><li><code>power::Real</code>: Tweedie power parameter (default: 1.5)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
tweedie_deviance(actual, predicted, power=1.5)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L689-L712">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.mean_poisson_deviance"><a class="docstring-binding" href="#UnifiedMetrics.mean_poisson_deviance"><code>UnifiedMetrics.mean_poisson_deviance</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">mean_poisson_deviance(actual, predicted)</code></pre><p>Compute the mean Poisson deviance.</p><p>Equivalent to <code>tweedie_deviance</code> with power=1. Appropriate for count data.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth non-negative vector (counts)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted positive vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 2, 3, 4, 5, 6]
predicted = [1.1, 1.9, 3.1, 3.9, 5.1, 5.9]
mean_poisson_deviance(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L760-L777">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.mean_gamma_deviance"><a class="docstring-binding" href="#UnifiedMetrics.mean_gamma_deviance"><code>UnifiedMetrics.mean_gamma_deviance</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">mean_gamma_deviance(actual, predicted)</code></pre><p>Compute the mean Gamma deviance.</p><p>Equivalent to <code>tweedie_deviance</code> with power=2. Appropriate for positive continuous targets with variance proportional to the square of the mean.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth positive vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted positive vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
mean_gamma_deviance(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L738-L756">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.d2_tweedie_score"><a class="docstring-binding" href="#UnifiedMetrics.d2_tweedie_score"><code>UnifiedMetrics.d2_tweedie_score</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">d2_tweedie_score(actual, predicted; power=1.5)</code></pre><p>Compute the D² (deviance explained) score using Tweedie deviance.</p><p>Similar to R² but uses Tweedie deviance instead of squared error. D² = 1 - deviance(actual, predicted) / deviance(actual, mean(actual))</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth non-negative vector</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted non-negative vector</li><li><code>power::Real</code>: Tweedie power parameter (default: 1.5)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
d2_tweedie_score(actual, predicted, power=1.5)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/regression.jl#L781-L800">source</a></section></details></article><h2 id="Classification-Metrics"><a class="docs-heading-anchor" href="#Classification-Metrics">Classification Metrics</a><a id="Classification-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Classification-Metrics" title="Permalink"></a></h2><h3 id="Accuracy-Metrics"><a class="docs-heading-anchor" href="#Accuracy-Metrics">Accuracy Metrics</a><a id="Accuracy-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Accuracy-Metrics" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.accuracy"><a class="docstring-binding" href="#UnifiedMetrics.accuracy"><code>UnifiedMetrics.accuracy</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">accuracy(actual, predicted)</code></pre><p>Compute the classification accuracy (proportion of correctly classified observations).</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector</code>: Ground truth vector</li><li><code>predicted::AbstractVector</code>: Predicted vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [&#39;a&#39;, &#39;a&#39;, &#39;c&#39;, &#39;b&#39;, &#39;c&#39;]
predicted = [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;b&#39;, &#39;a&#39;]
accuracy(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/classification.jl#L22-L37">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.ce"><a class="docstring-binding" href="#UnifiedMetrics.ce"><code>UnifiedMetrics.ce</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">ce(actual, predicted)</code></pre><p>Compute the classification error (proportion of misclassified observations).</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector</code>: Ground truth vector</li><li><code>predicted::AbstractVector</code>: Predicted vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [&#39;a&#39;, &#39;a&#39;, &#39;c&#39;, &#39;b&#39;, &#39;c&#39;]
predicted = [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;b&#39;, &#39;a&#39;]
ce(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/classification.jl#L1-L16">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.balanced_accuracy"><a class="docstring-binding" href="#UnifiedMetrics.balanced_accuracy"><code>UnifiedMetrics.balanced_accuracy</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">balanced_accuracy(actual, predicted)</code></pre><p>Compute balanced accuracy, which accounts for imbalanced datasets.</p><p>Balanced accuracy is the macro-averaged recall: the average of recall scores for each class. It gives equal weight to each class regardless of its frequency.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector</code>: Ground truth vector</li><li><code>predicted::AbstractVector</code>: Predicted vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 1, 1, 1, 0, 0]  # Imbalanced: 4 positives, 2 negatives
predicted = [1, 1, 1, 0, 0, 0]
balanced_accuracy(actual, predicted)  # (0.75 + 1.0) / 2 = 0.875</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/classification.jl#L143-L161">source</a></section></details></article><h3 id="Agreement-Metrics"><a class="docs-heading-anchor" href="#Agreement-Metrics">Agreement Metrics</a><a id="Agreement-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Agreement-Metrics" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.cohens_kappa"><a class="docstring-binding" href="#UnifiedMetrics.cohens_kappa"><code>UnifiedMetrics.cohens_kappa</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">cohens_kappa(actual, predicted)</code></pre><p>Compute Cohen&#39;s Kappa coefficient for inter-rater agreement.</p><p>Kappa measures agreement between two raters, accounting for agreement by chance.</p><ul><li>κ = 1: Perfect agreement</li><li>κ = 0: Agreement equivalent to chance</li><li>κ &lt; 0: Less agreement than chance</li></ul><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector</code>: Ground truth vector</li><li><code>predicted::AbstractVector</code>: Predicted vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [&#39;a&#39;, &#39;a&#39;, &#39;b&#39;, &#39;b&#39;, &#39;c&#39;, &#39;c&#39;]
predicted = [&#39;a&#39;, &#39;b&#39;, &#39;b&#39;, &#39;b&#39;, &#39;c&#39;, &#39;a&#39;]
cohens_kappa(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/classification.jl#L178-L198">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.ScoreQuadraticWeightedKappa"><a class="docstring-binding" href="#UnifiedMetrics.ScoreQuadraticWeightedKappa"><code>UnifiedMetrics.ScoreQuadraticWeightedKappa</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">ScoreQuadraticWeightedKappa(rater_a, rater_b; min_rating=nothing, max_rating=nothing)</code></pre><p>Compute the quadratic weighted kappa between two vectors of integer ratings.</p><p><strong>Arguments</strong></p><ul><li><code>rater_a::AbstractVector{&lt;:Integer}</code>: First rater&#39;s ratings</li><li><code>rater_b::AbstractVector{&lt;:Integer}</code>: Second rater&#39;s ratings</li><li><code>min_rating::Union{Integer,Nothing}</code>: Minimum possible rating (default: minimum of both vectors)</li><li><code>max_rating::Union{Integer,Nothing}</code>: Maximum possible rating (default: maximum of both vectors)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">rater_a = [1, 4, 5, 5, 2, 1]
rater_b = [2, 2, 4, 5, 3, 3]
ScoreQuadraticWeightedKappa(rater_a, rater_b, min_rating=1, max_rating=5)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/classification.jl#L42-L59">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.MeanQuadraticWeightedKappa"><a class="docstring-binding" href="#UnifiedMetrics.MeanQuadraticWeightedKappa"><code>UnifiedMetrics.MeanQuadraticWeightedKappa</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">MeanQuadraticWeightedKappa(kappas; weights=nothing)</code></pre><p>Compute the mean quadratic weighted kappa, optionally weighted.</p><p>Uses Fisher&#39;s z-transformation for averaging.</p><p><strong>Arguments</strong></p><ul><li><code>kappas::AbstractVector{&lt;:Real}</code>: Vector of kappa values</li><li><code>weights::Union{AbstractVector{&lt;:Real},Nothing}</code>: Optional weights (default: equal weights)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">kappas = [0.3, 0.2, 0.2, 0.5, 0.1, 0.2]
weights = [1.0, 2.5, 1.0, 1.0, 2.0, 3.0]
MeanQuadraticWeightedKappa(kappas, weights=weights)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/classification.jl#L104-L121">source</a></section></details></article><h3 id="Correlation-Metrics"><a class="docs-heading-anchor" href="#Correlation-Metrics">Correlation Metrics</a><a id="Correlation-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Correlation-Metrics" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.matthews_corrcoef"><a class="docstring-binding" href="#UnifiedMetrics.matthews_corrcoef"><code>UnifiedMetrics.matthews_corrcoef</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">matthews_corrcoef(actual, predicted)</code></pre><p>Compute the Matthews Correlation Coefficient (MCC) for binary classification.</p><p>MCC is considered one of the best metrics for binary classification, especially for imbalanced datasets. It returns a value in [-1, 1]:</p><ul><li>+1: Perfect prediction</li><li>0: Random prediction</li><li>-1: Total disagreement</li></ul><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Binary ground truth (1 for positive, 0 for negative)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Binary predictions (1 for positive, 0 for negative)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 1, 1, 0, 0, 0]
predicted = [1, 0, 1, 1, 0, 0]
matthews_corrcoef(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/classification.jl#L219-L240">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.mcc"><a class="docstring-binding" href="#UnifiedMetrics.mcc"><code>UnifiedMetrics.mcc</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">mcc(actual, predicted)</code></pre><p>Alias for <code>matthews_corrcoef</code>. Compute the Matthews Correlation Coefficient.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/classification.jl#L254-L258">source</a></section></details></article><h3 id="Confusion-Matrix"><a class="docs-heading-anchor" href="#Confusion-Matrix">Confusion Matrix</a><a id="Confusion-Matrix-1"></a><a class="docs-heading-anchor-permalink" href="#Confusion-Matrix" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.confusion_matrix"><a class="docstring-binding" href="#UnifiedMetrics.confusion_matrix"><code>UnifiedMetrics.confusion_matrix</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">confusion_matrix(actual, predicted)</code></pre><p>Compute the confusion matrix for classification.</p><p>Returns a dictionary with keys:</p><ul><li><code>:matrix</code> - The confusion matrix as a 2D array</li><li><code>:labels</code> - The class labels in order</li></ul><p>For binary classification with classes 0 and 1:</p><ul><li>matrix[1,1] = TN (true negatives)</li><li>matrix[1,2] = FP (false positives)</li><li>matrix[2,1] = FN (false negatives)</li><li>matrix[2,2] = TP (true positives)</li></ul><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector</code>: Ground truth vector</li><li><code>predicted::AbstractVector</code>: Predicted vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 1, 1, 0, 0, 0]
predicted = [1, 0, 1, 1, 0, 0]
cm = confusion_matrix(actual, predicted)
cm[:matrix]  # 2x2 confusion matrix
cm[:labels]  # [0, 1]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/classification.jl#L261-L288">source</a></section></details></article><h3 id="Top-K-Metrics"><a class="docs-heading-anchor" href="#Top-K-Metrics">Top-K Metrics</a><a id="Top-K-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Top-K-Metrics" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.top_k_accuracy"><a class="docstring-binding" href="#UnifiedMetrics.top_k_accuracy"><code>UnifiedMetrics.top_k_accuracy</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">top_k_accuracy(actual, predicted_probs, k)</code></pre><p>Compute top-k accuracy for multi-class classification.</p><p>Returns the fraction of samples where the true class is among the top k predictions.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Integer}</code>: Ground truth class indices (1-indexed)</li><li><code>predicted_probs::AbstractMatrix{&lt;:Real}</code>: Matrix of predicted probabilities (samples × classes)</li><li><code>k::Integer</code>: Number of top predictions to consider</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 2, 3, 1]
predicted_probs = [0.8 0.1 0.1;   # Sample 1: class 1 most likely
                   0.2 0.5 0.3;   # Sample 2: class 2 most likely
                   0.1 0.3 0.6;   # Sample 3: class 3 most likely
                   0.3 0.4 0.3]   # Sample 4: class 2 most likely (actual is 1)
top_k_accuracy(actual, predicted_probs, 1)  # Standard accuracy
top_k_accuracy(actual, predicted_probs, 2)  # Top-2 accuracy</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/classification.jl#L306-L328">source</a></section></details></article><h3 id="Loss-Functions"><a class="docs-heading-anchor" href="#Loss-Functions">Loss Functions</a><a id="Loss-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Loss-Functions" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.hamming_loss"><a class="docstring-binding" href="#UnifiedMetrics.hamming_loss"><code>UnifiedMetrics.hamming_loss</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">hamming_loss(actual, predicted)</code></pre><p>Compute the Hamming loss (fraction of misclassified labels).</p><p>For single-label classification, this equals the classification error (1 - accuracy). For multi-label classification, it measures the fraction of incorrect labels.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector</code>: Ground truth vector</li><li><code>predicted::AbstractVector</code>: Predicted vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [&#39;a&#39;, &#39;a&#39;, &#39;b&#39;, &#39;b&#39;, &#39;c&#39;, &#39;c&#39;]
predicted = [&#39;a&#39;, &#39;b&#39;, &#39;b&#39;, &#39;b&#39;, &#39;c&#39;, &#39;a&#39;]
hamming_loss(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/classification.jl#L348-L366">source</a></section><section><div><pre><code class="language-julia hljs">hamming_loss(actual, predicted)</code></pre><p>Compute Hamming loss for multi-label classification.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractMatrix{Bool}</code>: Ground truth binary matrix (samples × labels)</li><li><code>predicted::AbstractMatrix{Bool}</code>: Predicted binary matrix (samples × labels)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/classification.jl#L371-L379">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.zero_one_loss"><a class="docstring-binding" href="#UnifiedMetrics.zero_one_loss"><code>UnifiedMetrics.zero_one_loss</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">zero_one_loss(actual, predicted)</code></pre><p>Compute the zero-one loss (fraction of samples with any incorrect prediction).</p><p>For single-label classification, this equals the classification error.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector</code>: Ground truth vector</li><li><code>predicted::AbstractVector</code>: Predicted vector</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [&#39;a&#39;, &#39;a&#39;, &#39;b&#39;, &#39;b&#39;]
predicted = [&#39;a&#39;, &#39;b&#39;, &#39;b&#39;, &#39;b&#39;]
zero_one_loss(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/classification.jl#L385-L402">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.hinge_loss"><a class="docstring-binding" href="#UnifiedMetrics.hinge_loss"><code>UnifiedMetrics.hinge_loss</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">hinge_loss(actual, predicted)</code></pre><p>Compute the hinge loss for binary classification (used in SVMs).</p><p>Actual values should be -1 or 1. Predicted values are the decision function values (not probabilities).</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth (-1 or 1)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Decision function values (raw scores)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 1, -1, -1]
predicted = [0.8, 0.3, -0.5, 0.1]  # Decision function values
hinge_loss(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/classification.jl#L407-L425">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.squared_hinge_loss"><a class="docstring-binding" href="#UnifiedMetrics.squared_hinge_loss"><code>UnifiedMetrics.squared_hinge_loss</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">squared_hinge_loss(actual, predicted)</code></pre><p>Compute the squared hinge loss (used in some SVMs).</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth (-1 or 1)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Decision function values (raw scores)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 1, -1, -1]
predicted = [0.8, 0.3, -0.5, 0.1]
squared_hinge_loss(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/classification.jl#L431-L446">source</a></section></details></article><h2 id="Binary-Classification-Metrics"><a class="docs-heading-anchor" href="#Binary-Classification-Metrics">Binary Classification Metrics</a><a id="Binary-Classification-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Binary-Classification-Metrics" title="Permalink"></a></h2><h3 id="ROC-Based-Metrics"><a class="docs-heading-anchor" href="#ROC-Based-Metrics">ROC-Based Metrics</a><a id="ROC-Based-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#ROC-Based-Metrics" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.auc"><a class="docstring-binding" href="#UnifiedMetrics.auc"><code>UnifiedMetrics.auc</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">auc(actual, predicted)</code></pre><p>Compute the area under the ROC curve (AUC).</p><p>Uses the Mann-Whitney U statistic for fast computation without building the ROC curve.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Binary ground truth (1 for positive, 0 for negative)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted scores (higher = more likely positive)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 1, 1, 0, 0, 0]
predicted = [0.9, 0.8, 0.4, 0.5, 0.3, 0.2]
auc(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/binary_classification.jl#L1-L18">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.gini_coefficient"><a class="docstring-binding" href="#UnifiedMetrics.gini_coefficient"><code>UnifiedMetrics.gini_coefficient</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">gini_coefficient(actual, predicted)</code></pre><p>Compute the Gini coefficient from AUC.</p><p>Gini = 2 * AUC - 1</p><p>The Gini coefficient ranges from -1 to 1:</p><ul><li>1: Perfect prediction</li><li>0: Random prediction</li><li>-1: Perfectly wrong prediction</li></ul><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Binary ground truth (1 for positive, 0 for negative)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted scores (higher = more likely positive)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 1, 1, 0, 0, 0]
predicted = [0.9, 0.8, 0.4, 0.5, 0.3, 0.2]
gini_coefficient(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/binary_classification.jl#L309-L331">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.ks_statistic"><a class="docstring-binding" href="#UnifiedMetrics.ks_statistic"><code>UnifiedMetrics.ks_statistic</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">ks_statistic(actual, predicted)</code></pre><p>Compute the Kolmogorov-Smirnov statistic for binary classification.</p><p>KS statistic is the maximum difference between the cumulative distribution functions of positive and negative classes. Higher values indicate better discrimination.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Binary ground truth (1 for positive, 0 for negative)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted scores (higher = more likely positive)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 1, 1, 0, 0, 0]
predicted = [0.9, 0.8, 0.4, 0.5, 0.3, 0.2]
ks_statistic(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/binary_classification.jl#L336-L354">source</a></section></details></article><h3 id="Probability-Metrics"><a class="docs-heading-anchor" href="#Probability-Metrics">Probability Metrics</a><a id="Probability-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Probability-Metrics" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.ll"><a class="docstring-binding" href="#UnifiedMetrics.ll"><code>UnifiedMetrics.ll</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">ll(actual, predicted)</code></pre><p>Compute the elementwise log loss (cross-entropy loss).</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Binary ground truth (1 for positive, 0 for negative)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted probabilities for positive class</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 1, 1, 0, 0, 0]
predicted = [0.9, 0.8, 0.4, 0.5, 0.3, 0.2]
ll(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/binary_classification.jl#L29-L44">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.logloss"><a class="docstring-binding" href="#UnifiedMetrics.logloss"><code>UnifiedMetrics.logloss</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">logloss(actual, predicted)</code></pre><p>Compute the mean log loss (cross-entropy loss).</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Binary ground truth (1 for positive, 0 for negative)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted probabilities for positive class</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 1, 1, 0, 0, 0]
predicted = [0.9, 0.8, 0.4, 0.5, 0.3, 0.2]
logloss(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/binary_classification.jl#L62-L77">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.brier_score"><a class="docstring-binding" href="#UnifiedMetrics.brier_score"><code>UnifiedMetrics.brier_score</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">brier_score(actual, predicted)</code></pre><p>Compute the Brier score for probability predictions.</p><p>The Brier score is the mean squared error of predicted probabilities compared to binary outcomes. Lower is better (0 is perfect, 1 is worst).</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Binary ground truth (1 for positive, 0 for negative)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted probabilities for positive class [0, 1]</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 1, 1, 0, 0, 0]
predicted = [0.9, 0.8, 0.4, 0.5, 0.3, 0.2]
brier_score(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/binary_classification.jl#L285-L303">source</a></section></details></article><h3 id="Precision-and-Recall"><a class="docs-heading-anchor" href="#Precision-and-Recall">Precision and Recall</a><a id="Precision-and-Recall-1"></a><a class="docs-heading-anchor-permalink" href="#Precision-and-Recall" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.precision"><a class="docstring-binding" href="#UnifiedMetrics.precision"><code>UnifiedMetrics.precision</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">precision(actual, predicted)</code></pre><p>Compute precision (positive predictive value).</p><p>Proportion of positive predictions that are actually positive.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Binary ground truth (1 for positive, 0 for negative)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Binary predictions (1 for positive, 0 for negative)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 1, 1, 0, 0, 0]
predicted = [1, 1, 1, 1, 1, 1]
precision(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/binary_classification.jl#L82-L99">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.recall"><a class="docstring-binding" href="#UnifiedMetrics.recall"><code>UnifiedMetrics.recall</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">recall(actual, predicted)</code></pre><p>Compute recall (sensitivity, true positive rate).</p><p>Proportion of actual positives that are correctly predicted.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Binary ground truth (1 for positive, 0 for negative)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Binary predictions (1 for positive, 0 for negative)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 1, 1, 0, 0, 0]
predicted = [1, 0, 1, 1, 1, 1]
recall(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/binary_classification.jl#L110-L127">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.sensitivity"><a class="docstring-binding" href="#UnifiedMetrics.sensitivity"><code>UnifiedMetrics.sensitivity</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">sensitivity(actual, predicted)</code></pre><p>Alias for <code>recall</code>. Compute sensitivity (true positive rate).</p><p>Proportion of actual positives that are correctly predicted.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Binary ground truth (1 for positive, 0 for negative)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Binary predictions (1 for positive, 0 for negative)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/binary_classification.jl#L172-L182">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.specificity"><a class="docstring-binding" href="#UnifiedMetrics.specificity"><code>UnifiedMetrics.specificity</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">specificity(actual, predicted)</code></pre><p>Compute specificity (true negative rate, selectivity).</p><p>Proportion of actual negatives that are correctly predicted.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Binary ground truth (1 for positive, 0 for negative)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Binary predictions (1 for positive, 0 for negative)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 1, 1, 0, 0, 0]
predicted = [1, 0, 1, 1, 0, 0]
specificity(actual, predicted)  # 2/3 = 0.667</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/binary_classification.jl#L185-L202">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.npv"><a class="docstring-binding" href="#UnifiedMetrics.npv"><code>UnifiedMetrics.npv</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">npv(actual, predicted)</code></pre><p>Compute the Negative Predictive Value.</p><p>Proportion of negative predictions that are actually negative.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Binary ground truth (1 for positive, 0 for negative)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Binary predictions (1 for positive, 0 for negative)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 1, 1, 0, 0, 0]
predicted = [1, 0, 1, 1, 0, 0]
npv(actual, predicted)  # 2/3 = 0.667 (of negative predictions, 2 of 3 are correct)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/binary_classification.jl#L213-L230">source</a></section></details></article><h3 id="F-Score"><a class="docs-heading-anchor" href="#F-Score">F-Score</a><a id="F-Score-1"></a><a class="docs-heading-anchor-permalink" href="#F-Score" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.fbeta_score"><a class="docstring-binding" href="#UnifiedMetrics.fbeta_score"><code>UnifiedMetrics.fbeta_score</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">fbeta_score(actual, predicted; beta=1.0)</code></pre><p>Compute the F-beta score, a weighted harmonic mean of precision and recall.</p><p>When beta=1, this is the F1 score (equal weight to precision and recall). When beta&lt;1, precision is weighted more heavily. When beta&gt;1, recall is weighted more heavily.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Binary ground truth (1 for positive, 0 for negative)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Binary predictions (1 for positive, 0 for negative)</li><li><code>beta::Real</code>: Weight parameter (default: 1.0)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 1, 1, 0, 0, 0]
predicted = [1, 0, 1, 1, 1, 1]
fbeta_score(actual, predicted)  # F1 score
fbeta_score(actual, predicted, beta=0.5)  # F0.5 score (precision-weighted)
fbeta_score(actual, predicted, beta=2.0)  # F2 score (recall-weighted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/binary_classification.jl#L138-L160">source</a></section></details></article><h3 id="Error-Rates"><a class="docs-heading-anchor" href="#Error-Rates">Error Rates</a><a id="Error-Rates-1"></a><a class="docs-heading-anchor-permalink" href="#Error-Rates" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.fpr"><a class="docstring-binding" href="#UnifiedMetrics.fpr"><code>UnifiedMetrics.fpr</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">fpr(actual, predicted)</code></pre><p>Compute the False Positive Rate (fall-out, 1 - specificity).</p><p>Proportion of actual negatives that are incorrectly predicted as positive.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Binary ground truth (1 for positive, 0 for negative)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Binary predictions (1 for positive, 0 for negative)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 1, 1, 0, 0, 0]
predicted = [1, 0, 1, 1, 0, 0]
fpr(actual, predicted)  # 1/3 = 0.333</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/binary_classification.jl#L241-L258">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.fnr"><a class="docstring-binding" href="#UnifiedMetrics.fnr"><code>UnifiedMetrics.fnr</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">fnr(actual, predicted)</code></pre><p>Compute the False Negative Rate (miss rate, 1 - recall).</p><p>Proportion of actual positives that are incorrectly predicted as negative.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Binary ground truth (1 for positive, 0 for negative)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Binary predictions (1 for positive, 0 for negative)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 1, 1, 0, 0, 0]
predicted = [1, 0, 1, 1, 0, 0]
fnr(actual, predicted)  # 1/3 = 0.333</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/binary_classification.jl#L263-L280">source</a></section></details></article><h3 id="Combined-Metrics"><a class="docs-heading-anchor" href="#Combined-Metrics">Combined Metrics</a><a id="Combined-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Combined-Metrics" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.youden_j"><a class="docstring-binding" href="#UnifiedMetrics.youden_j"><code>UnifiedMetrics.youden_j</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">youden_j(actual, predicted)</code></pre><p>Compute Youden&#39;s J statistic (informedness).</p><p>J = sensitivity + specificity - 1 = TPR - FPR</p><p>Ranges from -1 to 1, where 1 indicates perfect prediction.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Binary ground truth (1 for positive, 0 for negative)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Binary predictions (1 for positive, 0 for negative)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 1, 1, 0, 0, 0]
predicted = [1, 0, 1, 1, 0, 0]
youden_j(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/binary_classification.jl#L445-L464">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.markedness"><a class="docstring-binding" href="#UnifiedMetrics.markedness"><code>UnifiedMetrics.markedness</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">markedness(actual, predicted)</code></pre><p>Compute markedness (deltaP, Δp).</p><p>Markedness = PPV + NPV - 1 = precision + NPV - 1</p><p>The counterpart to informedness (Youden&#39;s J) in the prediction direction.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Binary ground truth (1 for positive, 0 for negative)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Binary predictions (1 for positive, 0 for negative)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 1, 1, 0, 0, 0]
predicted = [1, 0, 1, 1, 0, 0]
markedness(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/binary_classification.jl#L469-L488">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.fowlkes_mallows_index"><a class="docstring-binding" href="#UnifiedMetrics.fowlkes_mallows_index"><code>UnifiedMetrics.fowlkes_mallows_index</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">fowlkes_mallows_index(actual, predicted)</code></pre><p>Compute the Fowlkes-Mallows index.</p><p>FM = sqrt(PPV × TPR) = sqrt(precision × recall)</p><p>Geometric mean of precision and recall, ranges from 0 to 1.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Binary ground truth (1 for positive, 0 for negative)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Binary predictions (1 for positive, 0 for negative)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 1, 1, 0, 0, 0]
predicted = [1, 0, 1, 1, 0, 0]
fowlkes_mallows_index(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/binary_classification.jl#L493-L512">source</a></section></details></article><h3 id="Likelihood-Ratios"><a class="docs-heading-anchor" href="#Likelihood-Ratios">Likelihood Ratios</a><a id="Likelihood-Ratios-1"></a><a class="docs-heading-anchor-permalink" href="#Likelihood-Ratios" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.positive_likelihood_ratio"><a class="docstring-binding" href="#UnifiedMetrics.positive_likelihood_ratio"><code>UnifiedMetrics.positive_likelihood_ratio</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">positive_likelihood_ratio(actual, predicted)</code></pre><p>Compute the Positive Likelihood Ratio (LR+).</p><p>LR+ = TPR / FPR = sensitivity / (1 - specificity)</p><p>Indicates how much more likely a positive prediction is for actual positives. Higher values are better.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Binary ground truth (1 for positive, 0 for negative)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Binary predictions (1 for positive, 0 for negative)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 1, 1, 0, 0, 0]
predicted = [1, 0, 1, 1, 0, 0]
positive_likelihood_ratio(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/binary_classification.jl#L519-L539">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.negative_likelihood_ratio"><a class="docstring-binding" href="#UnifiedMetrics.negative_likelihood_ratio"><code>UnifiedMetrics.negative_likelihood_ratio</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">negative_likelihood_ratio(actual, predicted)</code></pre><p>Compute the Negative Likelihood Ratio (LR-).</p><p>LR- = FNR / TNR = (1 - sensitivity) / specificity</p><p>Indicates how much more likely a negative prediction is for actual positives. Lower values are better.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Binary ground truth (1 for positive, 0 for negative)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Binary predictions (1 for positive, 0 for negative)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 1, 1, 0, 0, 0]
predicted = [1, 0, 1, 1, 0, 0]
negative_likelihood_ratio(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/binary_classification.jl#L546-L566">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.diagnostic_odds_ratio"><a class="docstring-binding" href="#UnifiedMetrics.diagnostic_odds_ratio"><code>UnifiedMetrics.diagnostic_odds_ratio</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">diagnostic_odds_ratio(actual, predicted)</code></pre><p>Compute the Diagnostic Odds Ratio (DOR).</p><p>DOR = LR+ / LR- = (TP × TN) / (FP × FN)</p><p>The ratio of the odds of a positive prediction in actual positives to the odds in actual negatives. Higher values indicate better discrimination.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Binary ground truth (1 for positive, 0 for negative)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Binary predictions (1 for positive, 0 for negative)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 1, 1, 0, 0, 0]
predicted = [1, 0, 1, 1, 0, 0]
diagnostic_odds_ratio(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/binary_classification.jl#L573-L593">source</a></section></details></article><h3 id="Business-Metrics"><a class="docs-heading-anchor" href="#Business-Metrics">Business Metrics</a><a id="Business-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Business-Metrics" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.lift"><a class="docstring-binding" href="#UnifiedMetrics.lift"><code>UnifiedMetrics.lift</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">lift(actual, predicted; percentile=0.1)</code></pre><p>Compute the lift at a given percentile.</p><p>Lift measures how much better the model is at identifying positives compared to random selection. Lift = (% positives in top X%) / (% positives overall).</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Binary ground truth (1 for positive, 0 for negative)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted scores (higher = more likely positive)</li><li><code>percentile::Real</code>: Top fraction to consider (default: 0.1 = top 10%)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 1, 1, 0, 0, 0, 0, 0, 0, 0]
predicted = [0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.0]
lift(actual, predicted, percentile=0.3)  # Lift in top 30%</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/binary_classification.jl#L376-L395">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.gain"><a class="docstring-binding" href="#UnifiedMetrics.gain"><code>UnifiedMetrics.gain</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">gain(actual, predicted; percentile=0.1)</code></pre><p>Compute the cumulative gain at a given percentile.</p><p>Gain measures what percentage of total positives are captured in the top X%.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Binary ground truth (1 for positive, 0 for negative)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted scores (higher = more likely positive)</li><li><code>percentile::Real</code>: Top fraction to consider (default: 0.1 = top 10%)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1, 1, 1, 0, 0, 0, 0, 0, 0, 0]
predicted = [0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.0]
gain(actual, predicted, percentile=0.3)  # What % of positives in top 30%</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/binary_classification.jl#L412-L430">source</a></section></details></article><h2 id="Information-Retrieval-Metrics"><a class="docs-heading-anchor" href="#Information-Retrieval-Metrics">Information Retrieval Metrics</a><a id="Information-Retrieval-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Information-Retrieval-Metrics" title="Permalink"></a></h2><h3 id="Set-Based-Metrics"><a class="docs-heading-anchor" href="#Set-Based-Metrics">Set-Based Metrics</a><a id="Set-Based-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Set-Based-Metrics" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.f1"><a class="docstring-binding" href="#UnifiedMetrics.f1"><code>UnifiedMetrics.f1</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">f1(actual, predicted)</code></pre><p>Compute the F1 score in the context of information retrieval.</p><p>Computes <code>2 * precision * recall / (precision + recall)</code> where precision is the proportion of retrieved documents that are relevant, and recall is the proportion of relevant documents that are retrieved.</p><p>Returns 0 if there are no true positives.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector</code>: Ground truth relevant documents (order doesn&#39;t matter)</li><li><code>predicted::AbstractVector</code>: Retrieved documents (order doesn&#39;t matter)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [&#39;a&#39;, &#39;c&#39;, &#39;d&#39;]
predicted = [&#39;d&#39;, &#39;e&#39;]
f1(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/information_retrieval.jl#L1-L22">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.precision_at_k"><a class="docstring-binding" href="#UnifiedMetrics.precision_at_k"><code>UnifiedMetrics.precision_at_k</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">precision_at_k(actual, predicted; k=10)</code></pre><p>Compute precision@k for information retrieval.</p><p>The fraction of top k predictions that are relevant.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector</code>: Ground truth relevant items</li><li><code>predicted::AbstractVector</code>: Ranked predictions (highest rank first)</li><li><code>k::Integer</code>: Number of top predictions to consider (default: 10)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;]
predicted = [&quot;a&quot;, &quot;x&quot;, &quot;b&quot;, &quot;y&quot;, &quot;z&quot;]
precision_at_k(actual, predicted, k=3)  # 2/3 (2 of top 3 are relevant)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/information_retrieval.jl#L325-L343">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.recall_at_k"><a class="docstring-binding" href="#UnifiedMetrics.recall_at_k"><code>UnifiedMetrics.recall_at_k</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">recall_at_k(actual, predicted; k=10)</code></pre><p>Compute recall@k for information retrieval.</p><p>The fraction of relevant items that appear in the top k predictions.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector</code>: Ground truth relevant items</li><li><code>predicted::AbstractVector</code>: Ranked predictions (highest rank first)</li><li><code>k::Integer</code>: Number of top predictions to consider (default: 10)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;]
predicted = [&quot;a&quot;, &quot;x&quot;, &quot;b&quot;, &quot;y&quot;, &quot;z&quot;]
recall_at_k(actual, predicted, k=3)  # 2/4 = 0.5 (found &quot;a&quot; and &quot;b&quot; in top 3)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/information_retrieval.jl#L294-L312">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.f1_at_k"><a class="docstring-binding" href="#UnifiedMetrics.f1_at_k"><code>UnifiedMetrics.f1_at_k</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">f1_at_k(actual, predicted; k=10)</code></pre><p>Compute F1@k for information retrieval.</p><p>Harmonic mean of precision@k and recall@k.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector</code>: Ground truth relevant items</li><li><code>predicted::AbstractVector</code>: Ranked predictions (highest rank first)</li><li><code>k::Integer</code>: Number of top predictions to consider (default: 10)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;]
predicted = [&quot;a&quot;, &quot;x&quot;, &quot;b&quot;, &quot;y&quot;, &quot;z&quot;]
f1_at_k(actual, predicted, k=3)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/information_retrieval.jl#L357-L375">source</a></section></details></article><h3 id="Ranking-Metrics"><a class="docs-heading-anchor" href="#Ranking-Metrics">Ranking Metrics</a><a id="Ranking-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Ranking-Metrics" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.dcg"><a class="docstring-binding" href="#UnifiedMetrics.dcg"><code>UnifiedMetrics.dcg</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">dcg(relevance; k=nothing)</code></pre><p>Compute the Discounted Cumulative Gain at position k.</p><p>DCG measures the usefulness of a ranking based on relevance scores, with a logarithmic discount to penalize relevant items appearing lower in the ranking.</p><p>DCG = Σ (2^rel_i - 1) / log2(i + 1)</p><p><strong>Arguments</strong></p><ul><li><code>relevance::AbstractVector{&lt;:Real}</code>: Relevance scores in ranked order (highest rank first)</li><li><code>k::Union{Integer,Nothing}</code>: Number of positions to consider (default: all)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">relevance = [3, 2, 3, 0, 1, 2]  # Relevance scores for ranked items
dcg(relevance)  # DCG for all positions
dcg(relevance, k=3)  # DCG@3</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/information_retrieval.jl#L115-L135">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.idcg"><a class="docstring-binding" href="#UnifiedMetrics.idcg"><code>UnifiedMetrics.idcg</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">idcg(relevance; k=nothing)</code></pre><p>Compute the Ideal Discounted Cumulative Gain at position k.</p><p>IDCG is the DCG of the best possible ranking (relevance scores sorted descending).</p><p><strong>Arguments</strong></p><ul><li><code>relevance::AbstractVector{&lt;:Real}</code>: Relevance scores (order doesn&#39;t matter)</li><li><code>k::Union{Integer,Nothing}</code>: Number of positions to consider (default: all)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">relevance = [3, 2, 3, 0, 1, 2]
idcg(relevance)  # Ideal DCG for all positions
idcg(relevance, k=3)  # Ideal DCG@3</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/information_retrieval.jl#L148-L165">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.ndcg"><a class="docstring-binding" href="#UnifiedMetrics.ndcg"><code>UnifiedMetrics.ndcg</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">ndcg(relevance; k=nothing)</code></pre><p>Compute the Normalized Discounted Cumulative Gain at position k.</p><p>NDCG = DCG / IDCG</p><p>Normalizes DCG to [0, 1] by dividing by the ideal DCG.</p><p><strong>Arguments</strong></p><ul><li><code>relevance::AbstractVector{&lt;:Real}</code>: Relevance scores in ranked order (highest rank first)</li><li><code>k::Union{Integer,Nothing}</code>: Number of positions to consider (default: all)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">relevance = [3, 2, 3, 0, 1, 2]  # Actual ranking
ndcg(relevance)  # NDCG for all positions
ndcg(relevance, k=3)  # NDCG@3</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/information_retrieval.jl#L171-L190">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.mean_ndcg"><a class="docstring-binding" href="#UnifiedMetrics.mean_ndcg"><code>UnifiedMetrics.mean_ndcg</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">mean_ndcg(relevances; k=nothing)</code></pre><p>Compute the mean NDCG over multiple queries.</p><p><strong>Arguments</strong></p><ul><li><code>relevances::AbstractVector{&lt;:AbstractVector{&lt;:Real}}</code>: List of relevance score vectors</li><li><code>k::Union{Integer,Nothing}</code>: Number of positions to consider (default: all)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">relevances = [[3, 2, 1, 0], [2, 1, 2, 1], [1, 1, 0, 0]]
mean_ndcg(relevances)  # Mean NDCG across queries
mean_ndcg(relevances, k=2)  # Mean NDCG@2</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/information_retrieval.jl#L387-L402">source</a></section></details></article><h3 id="Average-Precision"><a class="docs-heading-anchor" href="#Average-Precision">Average Precision</a><a id="Average-Precision-1"></a><a class="docs-heading-anchor-permalink" href="#Average-Precision" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.apk"><a class="docstring-binding" href="#UnifiedMetrics.apk"><code>UnifiedMetrics.apk</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">apk(k, actual, predicted)</code></pre><p>Compute the average precision at k.</p><p>Loops over the first k values of <code>predicted</code>. For each value that is in <code>actual</code> and hasn&#39;t been predicted before, increments the score by (number of hits so far) / position. Returns the final score divided by min(length(actual), k).</p><p>Returns <code>NaN</code> if <code>actual</code> is empty.</p><p><strong>Arguments</strong></p><ul><li><code>k::Integer</code>: Number of predictions to consider</li><li><code>actual::AbstractVector</code>: Ground truth relevant documents (order doesn&#39;t matter)</li><li><code>predicted::AbstractVector</code>: Retrieved documents in ranked order (most relevant first)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [&#39;a&#39;, &#39;b&#39;, &#39;d&#39;]
predicted = [&#39;b&#39;, &#39;c&#39;, &#39;a&#39;, &#39;e&#39;, &#39;f&#39;]
apk(3, actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/information_retrieval.jl#L40-L62">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.mapk"><a class="docstring-binding" href="#UnifiedMetrics.mapk"><code>UnifiedMetrics.mapk</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">mapk(k, actual, predicted)</code></pre><p>Compute the mean average precision at k.</p><p>Evaluates <code>apk</code> for each pair of elements from <code>actual</code> and <code>predicted</code> lists, then returns the mean.</p><p><strong>Arguments</strong></p><ul><li><code>k::Integer</code>: Number of predictions to consider for each query</li><li><code>actual::AbstractVector{&lt;:AbstractVector}</code>: List of ground truth vectors</li><li><code>predicted::AbstractVector{&lt;:AbstractVector}</code>: List of prediction vectors</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [[&#39;a&#39;, &#39;b&#39;], [&#39;a&#39;], [&#39;x&#39;, &#39;y&#39;, &#39;b&#39;]]
predicted = [[&#39;a&#39;, &#39;c&#39;, &#39;d&#39;], [&#39;x&#39;, &#39;b&#39;, &#39;a&#39;, &#39;b&#39;], [&#39;y&#39;]]
mapk(2, actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/information_retrieval.jl#L83-L102">source</a></section></details></article><h3 id="Reciprocal-Rank"><a class="docs-heading-anchor" href="#Reciprocal-Rank">Reciprocal Rank</a><a id="Reciprocal-Rank-1"></a><a class="docs-heading-anchor-permalink" href="#Reciprocal-Rank" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.reciprocal_rank"><a class="docstring-binding" href="#UnifiedMetrics.reciprocal_rank"><code>UnifiedMetrics.reciprocal_rank</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">reciprocal_rank(actual, predicted)</code></pre><p>Compute the Reciprocal Rank for a single query.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector</code>: Ground truth relevant items</li><li><code>predicted::AbstractVector</code>: Ranked predictions (highest rank first)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [&quot;a&quot;, &quot;b&quot;]
predicted = [&quot;c&quot;, &quot;a&quot;, &quot;b&quot;, &quot;d&quot;]
reciprocal_rank(actual, predicted)  # 1/2 = 0.5 (first relevant at position 2)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/information_retrieval.jl#L233-L248">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.mrr"><a class="docstring-binding" href="#UnifiedMetrics.mrr"><code>UnifiedMetrics.mrr</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">mrr(actual, predicted)</code></pre><p>Compute the Mean Reciprocal Rank.</p><p>MRR is the average of reciprocal ranks of the first relevant item for each query.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:AbstractVector}</code>: List of ground truth relevant items for each query</li><li><code>predicted::AbstractVector{&lt;:AbstractVector}</code>: List of ranked predictions for each query</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [[&quot;a&quot;, &quot;b&quot;], [&quot;c&quot;], [&quot;d&quot;, &quot;e&quot;]]
predicted = [[&quot;b&quot;, &quot;a&quot;, &quot;c&quot;], [&quot;a&quot;, &quot;c&quot;, &quot;d&quot;], [&quot;e&quot;, &quot;d&quot;, &quot;f&quot;]]
mrr(actual, predicted)  # (1/2 + 1/2 + 1/1) / 3 = 0.667</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/information_retrieval.jl#L196-L213">source</a></section></details></article><h3 id="Hit-Rate"><a class="docs-heading-anchor" href="#Hit-Rate">Hit Rate</a><a id="Hit-Rate-1"></a><a class="docs-heading-anchor-permalink" href="#Hit-Rate" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.hit_rate"><a class="docstring-binding" href="#UnifiedMetrics.hit_rate"><code>UnifiedMetrics.hit_rate</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">hit_rate(actual, predicted; k=10)</code></pre><p>Compute the hit rate (recall@k) for recommendation systems.</p><p>Hit rate is the fraction of queries where at least one relevant item appears in the top k predictions.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:AbstractVector}</code>: List of ground truth relevant items for each query</li><li><code>predicted::AbstractVector{&lt;:AbstractVector}</code>: List of ranked predictions for each query</li><li><code>k::Integer</code>: Number of top predictions to consider (default: 10)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [[&quot;a&quot;, &quot;b&quot;], [&quot;c&quot;], [&quot;d&quot;, &quot;e&quot;]]
predicted = [[&quot;a&quot;, &quot;x&quot;, &quot;y&quot;], [&quot;x&quot;, &quot;y&quot;, &quot;z&quot;], [&quot;e&quot;, &quot;f&quot;, &quot;g&quot;]]
hit_rate(actual, predicted, k=3)  # 2/3 queries have a hit in top 3</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/information_retrieval.jl#L259-L278">source</a></section></details></article><h3 id="Recommendation-Metrics"><a class="docs-heading-anchor" href="#Recommendation-Metrics">Recommendation Metrics</a><a id="Recommendation-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Recommendation-Metrics" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.coverage"><a class="docstring-binding" href="#UnifiedMetrics.coverage"><code>UnifiedMetrics.coverage</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">coverage(predicted, catalog)</code></pre><p>Compute the catalog coverage of recommendations.</p><p>Coverage measures what fraction of items in the catalog have been recommended at least once across all predictions.</p><p><strong>Arguments</strong></p><ul><li><code>predicted::AbstractVector{&lt;:AbstractVector}</code>: List of predictions for all queries</li><li><code>catalog::AbstractVector</code>: Full catalog of items</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">catalog = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, &quot;f&quot;]
predicted = [[&quot;a&quot;, &quot;b&quot;], [&quot;a&quot;, &quot;c&quot;], [&quot;b&quot;, &quot;d&quot;]]
coverage(predicted, catalog)  # 4/6 = 0.667 (recommended: a, b, c, d)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/information_retrieval.jl#L407-L425">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.novelty"><a class="docstring-binding" href="#UnifiedMetrics.novelty"><code>UnifiedMetrics.novelty</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">novelty(predicted, item_popularity)</code></pre><p>Compute the novelty of recommendations.</p><p>Novelty measures how unexpected/surprising the recommendations are, based on the popularity of recommended items. Higher novelty means recommending less popular (long-tail) items.</p><p><strong>Arguments</strong></p><ul><li><code>predicted::AbstractVector{&lt;:AbstractVector}</code>: List of predictions for all queries</li><li><code>item_popularity::Dict</code>: Dictionary mapping items to their popularity (0-1)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">popularity = Dict(&quot;a&quot; =&gt; 0.9, &quot;b&quot; =&gt; 0.5, &quot;c&quot; =&gt; 0.1, &quot;d&quot; =&gt; 0.05)
predicted = [[&quot;a&quot;, &quot;b&quot;], [&quot;c&quot;, &quot;d&quot;]]
novelty(predicted, popularity)  # Average -log2(popularity)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/information_retrieval.jl#L439-L458">source</a></section></details></article><h2 id="Time-Series-Metrics"><a class="docs-heading-anchor" href="#Time-Series-Metrics">Time Series Metrics</a><a id="Time-Series-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Time-Series-Metrics" title="Permalink"></a></h2><h3 id="Scaled-Error-Metrics"><a class="docs-heading-anchor" href="#Scaled-Error-Metrics">Scaled Error Metrics</a><a id="Scaled-Error-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Scaled-Error-Metrics" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.mase"><a class="docstring-binding" href="#UnifiedMetrics.mase"><code>UnifiedMetrics.mase</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">mase(actual, predicted; m=1)</code></pre><p>Compute the Mean Absolute Scaled Error for time series data.</p><p>MASE compares the prediction error to the error of a naive forecast. The naive forecast predicts the value from <code>m</code> periods ago (seasonal naive for m &gt; 1).</p><p>MASE &lt; 1 indicates the model outperforms the naive forecast. MASE = 1 indicates performance equal to naive forecast. MASE &gt; 1 indicates the model underperforms the naive forecast.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth time series (ordered by time)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted time series</li><li><code>m::Integer</code>: Seasonal period / frequency (default: 1)<ul><li><code>m=1</code>: Non-seasonal naive forecast (random walk)</li><li><code>m=4</code>: Quarterly seasonality (compare with same quarter last year)</li><li><code>m=7</code>: Weekly seasonality for daily data</li><li><code>m=12</code>: Monthly seasonality (compare with same month last year)</li><li><code>m=52</code>: Weekly seasonality for weekly data</li></ul></li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
mase(actual, predicted)  # Non-seasonal (m=1)
mase(actual, predicted, m=2)  # With seasonal period 2</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/time_series.jl#L1-L30">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.msse"><a class="docstring-binding" href="#UnifiedMetrics.msse"><code>UnifiedMetrics.msse</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">msse(actual, predicted; m=1)</code></pre><p>Compute the Mean Squared Scaled Error for time series data.</p><p>Similar to MASE but uses squared errors, making it more sensitive to large errors.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth time series (ordered by time)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted time series</li><li><code>m::Integer</code>: Seasonal period / frequency (default: 1)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
msse(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/time_series.jl#L46-L64">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.rmsse"><a class="docstring-binding" href="#UnifiedMetrics.rmsse"><code>UnifiedMetrics.rmsse</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">rmsse(actual, predicted; m=1)</code></pre><p>Compute the Root Mean Squared Scaled Error for time series data.</p><p>Square root of MSSE, on the same scale as the original data.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth time series (ordered by time)</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted time series</li><li><code>m::Integer</code>: Seasonal period / frequency (default: 1)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
rmsse(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/time_series.jl#L80-L98">source</a></section></details></article><h3 id="Bias-Metrics-2"><a class="docs-heading-anchor" href="#Bias-Metrics-2">Bias Metrics</a><a class="docs-heading-anchor-permalink" href="#Bias-Metrics-2" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.tracking_signal"><a class="docstring-binding" href="#UnifiedMetrics.tracking_signal"><code>UnifiedMetrics.tracking_signal</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">tracking_signal(actual, predicted)</code></pre><p>Compute the tracking signal for forecast monitoring.</p><p>Tracking signal = Cumulative Forecast Error / MAD</p><p>Used to detect forecast bias. Values outside [-4, 4] typically indicate bias.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth time series</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted time series</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [100, 110, 105, 115, 120]
predicted = [98, 108, 110, 112, 125]
tracking_signal(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/time_series.jl#L103-L122">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.forecast_bias"><a class="docstring-binding" href="#UnifiedMetrics.forecast_bias"><code>UnifiedMetrics.forecast_bias</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">forecast_bias(actual, predicted)</code></pre><p>Compute the forecast bias (cumulative forecast error normalized by number of periods).</p><p>Positive bias indicates systematic under-forecasting. Negative bias indicates systematic over-forecasting.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth time series</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted time series</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [100, 110, 105, 115, 120]
predicted = [98, 108, 110, 112, 125]
forecast_bias(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/time_series.jl#L133-L151">source</a></section></details></article><h3 id="Benchmark-Comparison"><a class="docs-heading-anchor" href="#Benchmark-Comparison">Benchmark Comparison</a><a id="Benchmark-Comparison-1"></a><a class="docs-heading-anchor-permalink" href="#Benchmark-Comparison" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.theil_u1"><a class="docstring-binding" href="#UnifiedMetrics.theil_u1"><code>UnifiedMetrics.theil_u1</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">theil_u1(actual, predicted)</code></pre><p>Compute Theil&#39;s U1 statistic (inequality coefficient).</p><p>U1 ranges from 0 to 1:</p><ul><li>0: Perfect forecast</li><li>1: Worst possible forecast</li></ul><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth time series</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted time series</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
theil_u1(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/time_series.jl#L157-L176">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.theil_u2"><a class="docstring-binding" href="#UnifiedMetrics.theil_u2"><code>UnifiedMetrics.theil_u2</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">theil_u2(actual, predicted; m=1)</code></pre><p>Compute Theil&#39;s U2 statistic (compares to naive forecast).</p><p>U2 &lt; 1: Model outperforms naive forecast U2 = 1: Model equals naive forecast U2 &gt; 1: Model underperforms naive forecast</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth time series</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted time series</li><li><code>m::Integer</code>: Seasonal period for naive forecast (default: 1)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2]
theil_u2(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/time_series.jl#L186-L206">source</a></section></details></article><h3 id="Percentage-Metrics"><a class="docs-heading-anchor" href="#Percentage-Metrics">Percentage Metrics</a><a id="Percentage-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Percentage-Metrics" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.wape"><a class="docstring-binding" href="#UnifiedMetrics.wape"><code>UnifiedMetrics.wape</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">wape(actual, predicted)</code></pre><p>Compute the Weighted Absolute Percentage Error for time series.</p><p>WAPE = Σ|actual - predicted| / Σ|actual|</p><p>Unlike MAPE, WAPE is well-defined when actual values are zero and gives more weight to larger values.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth time series</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted time series</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [100, 200, 150, 300, 250]
predicted = [110, 190, 160, 290, 260]
wape(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/time_series.jl#L223-L243">source</a></section></details></article><h3 id="Directional-Metrics"><a class="docs-heading-anchor" href="#Directional-Metrics">Directional Metrics</a><a id="Directional-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Directional-Metrics" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.directional_accuracy"><a class="docstring-binding" href="#UnifiedMetrics.directional_accuracy"><code>UnifiedMetrics.directional_accuracy</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">directional_accuracy(actual, predicted)</code></pre><p>Compute the directional accuracy (hit rate for direction of change).</p><p>Measures how often the forecast correctly predicts whether the value goes up or down.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth time series</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted time series</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [100, 110, 105, 115, 120]  # Changes: +10, -5, +10, +5
predicted = [100, 108, 106, 112, 118]  # Changes: +8, -2, +6, +6
directional_accuracy(actual, predicted)  # All directions match = 1.0</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/time_series.jl#L250-L267">source</a></section></details></article><h3 id="Prediction-Interval-Metrics"><a class="docs-heading-anchor" href="#Prediction-Interval-Metrics">Prediction Interval Metrics</a><a id="Prediction-Interval-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Prediction-Interval-Metrics" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.coverage_probability"><a class="docstring-binding" href="#UnifiedMetrics.coverage_probability"><code>UnifiedMetrics.coverage_probability</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">coverage_probability(actual, lower, upper)</code></pre><p>Compute the coverage probability of prediction intervals.</p><p>Measures what fraction of actual values fall within the prediction intervals.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth time series</li><li><code>lower::AbstractVector{&lt;:Real}</code>: Lower bounds of prediction intervals</li><li><code>upper::AbstractVector{&lt;:Real}</code>: Upper bounds of prediction intervals</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [100, 110, 105, 115, 120]
lower = [95, 105, 100, 108, 112]  # 95% lower bounds
upper = [105, 115, 112, 122, 128]  # 95% upper bounds
coverage_probability(actual, lower, upper)  # Should be ≈ 0.95 if well-calibrated</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/time_series.jl#L281-L300">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.pinball_loss_series"><a class="docstring-binding" href="#UnifiedMetrics.pinball_loss_series"><code>UnifiedMetrics.pinball_loss_series</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">pinball_loss_series(actual, predicted; quantile=0.5)</code></pre><p>Compute the pinball (quantile) loss for time series probabilistic forecasts.</p><p>Same as <code>quantile_loss</code> but named to be consistent with time series literature.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth time series</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Quantile forecast</li><li><code>quantile::Real</code>: Target quantile in (0, 1) (default: 0.5 = median)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [100, 110, 105, 115, 120]
predicted_median = [98, 108, 110, 112, 118]  # Median forecasts
pinball_loss_series(actual, predicted_median, quantile=0.5)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/time_series.jl#L306-L324">source</a></section></details></article><article><details class="docstring" open="true"><summary id="UnifiedMetrics.winkler_score"><a class="docstring-binding" href="#UnifiedMetrics.winkler_score"><code>UnifiedMetrics.winkler_score</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">winkler_score(actual, lower, upper; alpha=0.05)</code></pre><p>Compute the Winkler score for prediction interval evaluation.</p><p>The Winkler score rewards narrow intervals and penalizes intervals that don&#39;t contain the actual value.</p><p>Lower scores are better.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth time series</li><li><code>lower::AbstractVector{&lt;:Real}</code>: Lower bounds of prediction intervals</li><li><code>upper::AbstractVector{&lt;:Real}</code>: Upper bounds of prediction intervals</li><li><code>alpha::Real</code>: Significance level (default: 0.05 for 95% intervals)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [100, 110, 105, 115, 120]
lower = [95, 105, 100, 108, 112]
upper = [105, 115, 112, 122, 128]
winkler_score(actual, lower, upper, alpha=0.05)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/time_series.jl#L334-L357">source</a></section></details></article><h3 id="Autocorrelation-Metrics"><a class="docs-heading-anchor" href="#Autocorrelation-Metrics">Autocorrelation Metrics</a><a id="Autocorrelation-Metrics-1"></a><a class="docs-heading-anchor-permalink" href="#Autocorrelation-Metrics" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="UnifiedMetrics.autocorrelation_error"><a class="docstring-binding" href="#UnifiedMetrics.autocorrelation_error"><code>UnifiedMetrics.autocorrelation_error</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">autocorrelation_error(actual, predicted; max_lag=10)</code></pre><p>Compute the error in autocorrelation structure.</p><p>Measures how well the forecast preserves the autocorrelation structure of the actual series. Lower values indicate better preservation of temporal patterns.</p><p><strong>Arguments</strong></p><ul><li><code>actual::AbstractVector{&lt;:Real}</code>: Ground truth time series</li><li><code>predicted::AbstractVector{&lt;:Real}</code>: Predicted time series</li><li><code>max_lag::Integer</code>: Maximum lag to consider (default: 10)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">actual = [1.1, 1.9, 3.0, 4.4, 5.0, 5.6, 6.2, 7.1, 8.0, 9.2]
predicted = [0.9, 1.8, 2.5, 4.5, 5.0, 6.2, 6.0, 7.0, 8.1, 9.0]
autocorrelation_error(actual, predicted)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/taf-society/UnifiedMetrics.jl/blob/91dc6fe6fa152e9474ec6cdb65b2f9636e1dccf7/src/time_series.jl#L378-L397">source</a></section></details></article><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><ul><li><a href="#UnifiedMetrics.MeanQuadraticWeightedKappa"><code>UnifiedMetrics.MeanQuadraticWeightedKappa</code></a></li><li><a href="#UnifiedMetrics.ScoreQuadraticWeightedKappa"><code>UnifiedMetrics.ScoreQuadraticWeightedKappa</code></a></li><li><a href="#UnifiedMetrics.accuracy"><code>UnifiedMetrics.accuracy</code></a></li><li><a href="#UnifiedMetrics.adjusted_r2"><code>UnifiedMetrics.adjusted_r2</code></a></li><li><a href="#UnifiedMetrics.ae"><code>UnifiedMetrics.ae</code></a></li><li><a href="#UnifiedMetrics.ape"><code>UnifiedMetrics.ape</code></a></li><li><a href="#UnifiedMetrics.apk"><code>UnifiedMetrics.apk</code></a></li><li><a href="#UnifiedMetrics.auc"><code>UnifiedMetrics.auc</code></a></li><li><a href="#UnifiedMetrics.autocorrelation_error"><code>UnifiedMetrics.autocorrelation_error</code></a></li><li><a href="#UnifiedMetrics.balanced_accuracy"><code>UnifiedMetrics.balanced_accuracy</code></a></li><li><a href="#UnifiedMetrics.bias"><code>UnifiedMetrics.bias</code></a></li><li><a href="#UnifiedMetrics.brier_score"><code>UnifiedMetrics.brier_score</code></a></li><li><a href="#UnifiedMetrics.ce"><code>UnifiedMetrics.ce</code></a></li><li><a href="#UnifiedMetrics.cohens_kappa"><code>UnifiedMetrics.cohens_kappa</code></a></li><li><a href="#UnifiedMetrics.confusion_matrix"><code>UnifiedMetrics.confusion_matrix</code></a></li><li><a href="#UnifiedMetrics.coverage"><code>UnifiedMetrics.coverage</code></a></li><li><a href="#UnifiedMetrics.coverage_probability"><code>UnifiedMetrics.coverage_probability</code></a></li><li><a href="#UnifiedMetrics.d2_tweedie_score"><code>UnifiedMetrics.d2_tweedie_score</code></a></li><li><a href="#UnifiedMetrics.dcg"><code>UnifiedMetrics.dcg</code></a></li><li><a href="#UnifiedMetrics.diagnostic_odds_ratio"><code>UnifiedMetrics.diagnostic_odds_ratio</code></a></li><li><a href="#UnifiedMetrics.directional_accuracy"><code>UnifiedMetrics.directional_accuracy</code></a></li><li><a href="#UnifiedMetrics.explained_variation"><code>UnifiedMetrics.explained_variation</code></a></li><li><a href="#UnifiedMetrics.f1"><code>UnifiedMetrics.f1</code></a></li><li><a href="#UnifiedMetrics.f1_at_k"><code>UnifiedMetrics.f1_at_k</code></a></li><li><a href="#UnifiedMetrics.fbeta_score"><code>UnifiedMetrics.fbeta_score</code></a></li><li><a href="#UnifiedMetrics.fnr"><code>UnifiedMetrics.fnr</code></a></li><li><a href="#UnifiedMetrics.forecast_bias"><code>UnifiedMetrics.forecast_bias</code></a></li><li><a href="#UnifiedMetrics.fowlkes_mallows_index"><code>UnifiedMetrics.fowlkes_mallows_index</code></a></li><li><a href="#UnifiedMetrics.fpr"><code>UnifiedMetrics.fpr</code></a></li><li><a href="#UnifiedMetrics.gain"><code>UnifiedMetrics.gain</code></a></li><li><a href="#UnifiedMetrics.gini_coefficient"><code>UnifiedMetrics.gini_coefficient</code></a></li><li><a href="#UnifiedMetrics.hamming_loss"><code>UnifiedMetrics.hamming_loss</code></a></li><li><a href="#UnifiedMetrics.hinge_loss"><code>UnifiedMetrics.hinge_loss</code></a></li><li><a href="#UnifiedMetrics.hit_rate"><code>UnifiedMetrics.hit_rate</code></a></li><li><a href="#UnifiedMetrics.huber_loss"><code>UnifiedMetrics.huber_loss</code></a></li><li><a href="#UnifiedMetrics.idcg"><code>UnifiedMetrics.idcg</code></a></li><li><a href="#UnifiedMetrics.ks_statistic"><code>UnifiedMetrics.ks_statistic</code></a></li><li><a href="#UnifiedMetrics.lift"><code>UnifiedMetrics.lift</code></a></li><li><a href="#UnifiedMetrics.ll"><code>UnifiedMetrics.ll</code></a></li><li><a href="#UnifiedMetrics.log_cosh_loss"><code>UnifiedMetrics.log_cosh_loss</code></a></li><li><a href="#UnifiedMetrics.logloss"><code>UnifiedMetrics.logloss</code></a></li><li><a href="#UnifiedMetrics.mae"><code>UnifiedMetrics.mae</code></a></li><li><a href="#UnifiedMetrics.mape"><code>UnifiedMetrics.mape</code></a></li><li><a href="#UnifiedMetrics.mapk"><code>UnifiedMetrics.mapk</code></a></li><li><a href="#UnifiedMetrics.markedness"><code>UnifiedMetrics.markedness</code></a></li><li><a href="#UnifiedMetrics.mase"><code>UnifiedMetrics.mase</code></a></li><li><a href="#UnifiedMetrics.matthews_corrcoef"><code>UnifiedMetrics.matthews_corrcoef</code></a></li><li><a href="#UnifiedMetrics.max_ae"><code>UnifiedMetrics.max_ae</code></a></li><li><a href="#UnifiedMetrics.max_error"><code>UnifiedMetrics.max_error</code></a></li><li><a href="#UnifiedMetrics.mcc"><code>UnifiedMetrics.mcc</code></a></li><li><a href="#UnifiedMetrics.mdae"><code>UnifiedMetrics.mdae</code></a></li><li><a href="#UnifiedMetrics.mean_gamma_deviance"><code>UnifiedMetrics.mean_gamma_deviance</code></a></li><li><a href="#UnifiedMetrics.mean_ndcg"><code>UnifiedMetrics.mean_ndcg</code></a></li><li><a href="#UnifiedMetrics.mean_poisson_deviance"><code>UnifiedMetrics.mean_poisson_deviance</code></a></li><li><a href="#UnifiedMetrics.mpe"><code>UnifiedMetrics.mpe</code></a></li><li><a href="#UnifiedMetrics.mrr"><code>UnifiedMetrics.mrr</code></a></li><li><a href="#UnifiedMetrics.mse"><code>UnifiedMetrics.mse</code></a></li><li><a href="#UnifiedMetrics.msle"><code>UnifiedMetrics.msle</code></a></li><li><a href="#UnifiedMetrics.msse"><code>UnifiedMetrics.msse</code></a></li><li><a href="#UnifiedMetrics.ndcg"><code>UnifiedMetrics.ndcg</code></a></li><li><a href="#UnifiedMetrics.negative_likelihood_ratio"><code>UnifiedMetrics.negative_likelihood_ratio</code></a></li><li><a href="#UnifiedMetrics.novelty"><code>UnifiedMetrics.novelty</code></a></li><li><a href="#UnifiedMetrics.npv"><code>UnifiedMetrics.npv</code></a></li><li><a href="#UnifiedMetrics.nrmse"><code>UnifiedMetrics.nrmse</code></a></li><li><a href="#UnifiedMetrics.percent_bias"><code>UnifiedMetrics.percent_bias</code></a></li><li><a href="#UnifiedMetrics.pinball_loss"><code>UnifiedMetrics.pinball_loss</code></a></li><li><a href="#UnifiedMetrics.pinball_loss_series"><code>UnifiedMetrics.pinball_loss_series</code></a></li><li><a href="#UnifiedMetrics.positive_likelihood_ratio"><code>UnifiedMetrics.positive_likelihood_ratio</code></a></li><li><a href="#UnifiedMetrics.precision"><code>UnifiedMetrics.precision</code></a></li><li><a href="#UnifiedMetrics.precision_at_k"><code>UnifiedMetrics.precision_at_k</code></a></li><li><a href="#UnifiedMetrics.quantile_loss"><code>UnifiedMetrics.quantile_loss</code></a></li><li><a href="#UnifiedMetrics.rae"><code>UnifiedMetrics.rae</code></a></li><li><a href="#UnifiedMetrics.recall"><code>UnifiedMetrics.recall</code></a></li><li><a href="#UnifiedMetrics.recall_at_k"><code>UnifiedMetrics.recall_at_k</code></a></li><li><a href="#UnifiedMetrics.reciprocal_rank"><code>UnifiedMetrics.reciprocal_rank</code></a></li><li><a href="#UnifiedMetrics.rmse"><code>UnifiedMetrics.rmse</code></a></li><li><a href="#UnifiedMetrics.rmsle"><code>UnifiedMetrics.rmsle</code></a></li><li><a href="#UnifiedMetrics.rmsse"><code>UnifiedMetrics.rmsse</code></a></li><li><a href="#UnifiedMetrics.rrse"><code>UnifiedMetrics.rrse</code></a></li><li><a href="#UnifiedMetrics.rse"><code>UnifiedMetrics.rse</code></a></li><li><a href="#UnifiedMetrics.se"><code>UnifiedMetrics.se</code></a></li><li><a href="#UnifiedMetrics.sensitivity"><code>UnifiedMetrics.sensitivity</code></a></li><li><a href="#UnifiedMetrics.sle"><code>UnifiedMetrics.sle</code></a></li><li><a href="#UnifiedMetrics.smape"><code>UnifiedMetrics.smape</code></a></li><li><a href="#UnifiedMetrics.specificity"><code>UnifiedMetrics.specificity</code></a></li><li><a href="#UnifiedMetrics.squared_hinge_loss"><code>UnifiedMetrics.squared_hinge_loss</code></a></li><li><a href="#UnifiedMetrics.sse"><code>UnifiedMetrics.sse</code></a></li><li><a href="#UnifiedMetrics.theil_u1"><code>UnifiedMetrics.theil_u1</code></a></li><li><a href="#UnifiedMetrics.theil_u2"><code>UnifiedMetrics.theil_u2</code></a></li><li><a href="#UnifiedMetrics.top_k_accuracy"><code>UnifiedMetrics.top_k_accuracy</code></a></li><li><a href="#UnifiedMetrics.tracking_signal"><code>UnifiedMetrics.tracking_signal</code></a></li><li><a href="#UnifiedMetrics.tweedie_deviance"><code>UnifiedMetrics.tweedie_deviance</code></a></li><li><a href="#UnifiedMetrics.wape"><code>UnifiedMetrics.wape</code></a></li><li><a href="#UnifiedMetrics.winkler_score"><code>UnifiedMetrics.winkler_score</code></a></li><li><a href="#UnifiedMetrics.wmape"><code>UnifiedMetrics.wmape</code></a></li><li><a href="#UnifiedMetrics.youden_j"><code>UnifiedMetrics.youden_j</code></a></li><li><a href="#UnifiedMetrics.zero_one_loss"><code>UnifiedMetrics.zero_one_loss</code></a></li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../information_retrieval/">« Information Retrieval</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Friday 30 January 2026 10:09">Friday 30 January 2026</span>. Using Julia version 1.11.8.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
